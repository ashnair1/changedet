{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":""},{"location":"index.html#changedet","title":"changedet","text":"<p>Experimental repo for trying out classical change detection algorithms. Refer docs for further details.</p>"},{"location":"SUMMARY.html","title":"SUMMARY","text":"<ul> <li>Home</li> <li>Installation</li> <li>Usage</li> <li>API Reference</li> </ul>"},{"location":"installation.html","title":"Installation","text":"Installation"},{"location":"installation.html#from-source","title":"From source","text":"<p>The source for changedet can be downloaded from the Github repo.</p> <p>You can either clone the public repository:</p> <pre><code>git clone git://github.com/ashnair1/changedet\n</code></pre> <p>Or download the tarball:</p> <pre><code>curl -OJL https://github.com/ashnair1/changedet/tarball/master\n</code></pre> <p>Once you have a copy of the source, you can install it with:</p> <pre><code>pip install .\n</code></pre>"},{"location":"usage.html","title":"Usage","text":"Usage  <p>Changedet uses fire for its CLI. Basic usage commands are given below.</p> <ul> <li>For running change detection on two images, you can run the following command</li> </ul> <pre><code>changedet --algo imgdiff run sample1.tif sample2.tif\n</code></pre> <ul> <li>Get more information on algorithm used</li> </ul> <pre><code>changedet --algo imgdiff algo_obj --help\n</code></pre> <ul> <li>Get more info on changedet pipeline</li> </ul> <pre><code>changedet --help\n</code></pre> <ul> <li>List available algorithms</li> </ul> <pre><code>changedet list\n</code></pre>"},{"location":"reference/SUMMARY.html","title":"SUMMARY","text":"<ul> <li>changedet<ul> <li>algos<ul> <li>base</li> <li>catalog</li> <li>cva</li> <li>imgdiff</li> <li>ipca</li> <li>irmad</li> </ul> </li> <li>cli</li> <li>pipeline</li> <li>utils</li> </ul> </li> </ul>"},{"location":"reference/cli.html","title":"cli","text":"<p>Console script for changedet.</p>"},{"location":"reference/pipeline.html","title":"pipeline","text":""},{"location":"reference/pipeline.html#changedet.pipeline.ChangeDetPipeline","title":"<code>ChangeDetPipeline</code>","text":"<p>Basic pipeline for running change detection algorithms.</p> <p>Parameters:</p> Name Type Description Default <code>algo</code> <code>str</code> <p>Change detection algorithm to be used</p> required <p>Attributes:</p> Name Type Description <code>algo_name</code> <code>str</code> <p>Name of change detection algorithm</p> <code>algo_obj</code> <code>str</code> <p>Change detection algorithm object</p> <code>logger</code> <code>Logger</code> <p>Logger object</p> Source code in <code>changedet/pipeline.py</code> <pre><code>class ChangeDetPipeline:\n    \"\"\"\n    Basic pipeline for running change detection algorithms.\n\n    Args:\n        algo (str): Change detection algorithm to be used\n\n    Attributes:\n        algo_name (str): Name of change detection algorithm\n        algo_obj (str): Change detection algorithm object\n        logger (logging.Logger): Logger object\n\n    \"\"\"\n\n    def __init__(self, algo: str):\n        \"\"\"Initialise Pipeline\n\n        Args:\n            algo (str): Change detection algorithm to be used\n        \"\"\"\n        self.algo_name = algo\n        self.algo_obj = AlgoCatalog.get(algo)\n        self.logger = init_logger(\"changedet\")\n\n    # Image loading and sanity checks should be done here\n    def read(self, im1: str, im2: str, band: int) -&gt; tuple[np.ndarray, np.ndarray]:\n        \"\"\"Read and prepare images\n\n        Args:\n            im1 (str): Path to image 1\n            im2 (str): Path to image 2\n            band (int): Band selection\n\n        Raises:\n            AssertionError: If images are not in the same projection system\n            AssertionError: If images are not of same shape\n\n        Returns:\n            tuple:\n                - arr1 (numpy.ndarray): Image 1 array of shape (B, H, W)\n                - arr2 (numpy.ndarray): Image 2 array of shape (B, H, W)\n        \"\"\"\n        try:\n            assert Path(im1).exists() and Path(im2).exists()\n        except AssertionError:\n            self.logger.critical(\"Images not found\")\n            raise\n\n        arr1, crs1, self.meta1 = self._read(im1, band)\n        arr2, crs2, self.meta2 = self._read(im2, band)\n\n        try:\n            assert crs1 == crs2\n        except AssertionError:\n            self.logger.critical(\"Images are not in the same projection system\")\n            raise\n\n        try:\n            assert arr1.shape == arr2.shape\n        except AssertionError:\n            self.logger.critical(\"Image array shapes do not match\")\n            raise\n\n        return arr1, arr2\n\n    def _read(self, im: str, band: int) -&gt; tuple[np.ndarray, CRS, Profile]:\n        with rio.open(im) as raster:\n            profile = raster.profile\n            crs = raster.crs\n\n            if band == -1:\n                arr = raster.read()\n            else:\n                arr = np.expand_dims(raster.read(band), axis=0)\n        return arr, crs, profile\n\n    def run(self, im1: str, im2: str, band: int = -1, **kwargs: Any) -&gt; None:\n        \"\"\"\n        Run change detection on images\n\n        Args:\n            im1 (str): Path to image 1\n            im2 (str): Path to image 2\n            band (int): Band selection\n\n        Raises:\n            AssertionError: If no algorithm is specified\n        \"\"\"\n        if not self.algo_obj:\n            raise AssertionError(\"Algorithm not specified\")\n        im1a, im2a = self.read(im1, im2, band)\n        # TODO: Decide whether algos should have their own loggers\n        kwargs.update({\"logger\": self.logger, \"band\": band})\n        cmap = self.algo_obj.run(im1a, im2a, **kwargs)\n        self.write(cmap)\n\n    def write(self, cmap: np.ndarray) -&gt; None:\n        \"\"\"Write change map to disk\n\n        Args:\n            cmap (numpy.ndarray): Change map of shape (B, H, W)\n\n        \"\"\"\n\n        profile = self.meta1\n        outfile = f\"{self.algo_name}_cmap.tif\"\n\n        # Bandwise change or Single band change\n        cmap = np.expand_dims(cmap, axis=0) if len(cmap.shape) == 2 else cmap\n\n        profile[\"count\"] = cmap.shape[0]\n\n        with rio.Env():\n            with rio.open(outfile, \"w\", **profile) as dst:\n                for i in range(profile[\"count\"]):\n                    dst.write(cmap[i], i + 1)\n        self.logger.info(\"Change map written to %s\", outfile)\n\n    @classmethod\n    def list(cls) -&gt; None:\n        \"\"\"List available algorithms\"\"\"\n        print(AlgoCatalog.list())\n</code></pre>"},{"location":"reference/pipeline.html#changedet.pipeline.ChangeDetPipeline.__init__","title":"<code>__init__(algo)</code>","text":"<p>Initialise Pipeline</p> <p>Parameters:</p> Name Type Description Default <code>algo</code> <code>str</code> <p>Change detection algorithm to be used</p> required Source code in <code>changedet/pipeline.py</code> <pre><code>def __init__(self, algo: str):\n    \"\"\"Initialise Pipeline\n\n    Args:\n        algo (str): Change detection algorithm to be used\n    \"\"\"\n    self.algo_name = algo\n    self.algo_obj = AlgoCatalog.get(algo)\n    self.logger = init_logger(\"changedet\")\n</code></pre>"},{"location":"reference/pipeline.html#changedet.pipeline.ChangeDetPipeline.list","title":"<code>list()</code>  <code>classmethod</code>","text":"<p>List available algorithms</p> Source code in <code>changedet/pipeline.py</code> <pre><code>@classmethod\ndef list(cls) -&gt; None:\n    \"\"\"List available algorithms\"\"\"\n    print(AlgoCatalog.list())\n</code></pre>"},{"location":"reference/pipeline.html#changedet.pipeline.ChangeDetPipeline.read","title":"<code>read(im1, im2, band)</code>","text":"<p>Read and prepare images</p> <p>Parameters:</p> Name Type Description Default <code>im1</code> <code>str</code> <p>Path to image 1</p> required <code>im2</code> <code>str</code> <p>Path to image 2</p> required <code>band</code> <code>int</code> <p>Band selection</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>If images are not in the same projection system</p> <code>AssertionError</code> <p>If images are not of same shape</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[ndarray, ndarray]</code> <ul> <li>arr1 (numpy.ndarray): Image 1 array of shape (B, H, W)</li> <li>arr2 (numpy.ndarray): Image 2 array of shape (B, H, W)</li> </ul> Source code in <code>changedet/pipeline.py</code> <pre><code>def read(self, im1: str, im2: str, band: int) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Read and prepare images\n\n    Args:\n        im1 (str): Path to image 1\n        im2 (str): Path to image 2\n        band (int): Band selection\n\n    Raises:\n        AssertionError: If images are not in the same projection system\n        AssertionError: If images are not of same shape\n\n    Returns:\n        tuple:\n            - arr1 (numpy.ndarray): Image 1 array of shape (B, H, W)\n            - arr2 (numpy.ndarray): Image 2 array of shape (B, H, W)\n    \"\"\"\n    try:\n        assert Path(im1).exists() and Path(im2).exists()\n    except AssertionError:\n        self.logger.critical(\"Images not found\")\n        raise\n\n    arr1, crs1, self.meta1 = self._read(im1, band)\n    arr2, crs2, self.meta2 = self._read(im2, band)\n\n    try:\n        assert crs1 == crs2\n    except AssertionError:\n        self.logger.critical(\"Images are not in the same projection system\")\n        raise\n\n    try:\n        assert arr1.shape == arr2.shape\n    except AssertionError:\n        self.logger.critical(\"Image array shapes do not match\")\n        raise\n\n    return arr1, arr2\n</code></pre>"},{"location":"reference/pipeline.html#changedet.pipeline.ChangeDetPipeline.run","title":"<code>run(im1, im2, band=-1, **kwargs)</code>","text":"<p>Run change detection on images</p> <p>Parameters:</p> Name Type Description Default <code>im1</code> <code>str</code> <p>Path to image 1</p> required <code>im2</code> <code>str</code> <p>Path to image 2</p> required <code>band</code> <code>int</code> <p>Band selection</p> <code>-1</code> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If no algorithm is specified</p> Source code in <code>changedet/pipeline.py</code> <pre><code>def run(self, im1: str, im2: str, band: int = -1, **kwargs: Any) -&gt; None:\n    \"\"\"\n    Run change detection on images\n\n    Args:\n        im1 (str): Path to image 1\n        im2 (str): Path to image 2\n        band (int): Band selection\n\n    Raises:\n        AssertionError: If no algorithm is specified\n    \"\"\"\n    if not self.algo_obj:\n        raise AssertionError(\"Algorithm not specified\")\n    im1a, im2a = self.read(im1, im2, band)\n    # TODO: Decide whether algos should have their own loggers\n    kwargs.update({\"logger\": self.logger, \"band\": band})\n    cmap = self.algo_obj.run(im1a, im2a, **kwargs)\n    self.write(cmap)\n</code></pre>"},{"location":"reference/pipeline.html#changedet.pipeline.ChangeDetPipeline.write","title":"<code>write(cmap)</code>","text":"<p>Write change map to disk</p> <p>Parameters:</p> Name Type Description Default <code>cmap</code> <code>ndarray</code> <p>Change map of shape (B, H, W)</p> required Source code in <code>changedet/pipeline.py</code> <pre><code>def write(self, cmap: np.ndarray) -&gt; None:\n    \"\"\"Write change map to disk\n\n    Args:\n        cmap (numpy.ndarray): Change map of shape (B, H, W)\n\n    \"\"\"\n\n    profile = self.meta1\n    outfile = f\"{self.algo_name}_cmap.tif\"\n\n    # Bandwise change or Single band change\n    cmap = np.expand_dims(cmap, axis=0) if len(cmap.shape) == 2 else cmap\n\n    profile[\"count\"] = cmap.shape[0]\n\n    with rio.Env():\n        with rio.open(outfile, \"w\", **profile) as dst:\n            for i in range(profile[\"count\"]):\n                dst.write(cmap[i], i + 1)\n    self.logger.info(\"Change map written to %s\", outfile)\n</code></pre>"},{"location":"reference/utils.html","title":"utils","text":""},{"location":"reference/utils.html#changedet.utils.GMM","title":"<code>GMM</code>","text":"Source code in <code>changedet/utils.py</code> <pre><code>class GMM:\n    def __init__(\n        self,\n        K: int,\n        niter: int = 100,\n        *,\n        cov_type: str = \"full\",\n        tol: float = 1e-4,\n        reg_covar: float = 1e-6,\n    ):\n        self.n_components = K\n        self.cov_type = cov_type\n        self.tol = tol\n        self.niter = niter\n        self.reg_covar = reg_covar\n\n    def init_cluster_params(\n        self, X: np.ndarray\n    ) -&gt; tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"Initialse cluster parameters\n\n        Shape notation:\n\n            N: number of samples\n            D: number of features\n            K: number of mixture components\n\n        Initialisation method:\n\n            Initialise means to a random data point in X\n            Initialse cov to a spherical covariance matrix of variance 1\n            Initialse pi to uniform distribution\n\n        Args:\n            X (numpy.ndarray): Data matrix of shape (N,D)\n\n        Returns:\n            tuple:\n                - means (numpy.ndarray): Means array of shape (K, D)\n                - cov (numpy.ndarray): Covariance matrix of shape (K,D,D)\n                - pi (numpy.ndarray): Mixture weights of shape (K,)\n        \"\"\"\n\n        n_samples, n_features = X.shape\n        means = np.zeros((self.n_components, n_features))\n        cov = np.zeros((self.n_components, n_features, n_features))\n\n        # Initialise\n        # Mean -&gt; random data point\n        # Cov -&gt; spherical covariance - all clusters have same diagonal cov\n        # matrix and diagonal elements are all equal\n        for k in range(self.n_components):\n            means[k] = X[np.random.choice(n_samples)]\n            cov[k] = np.eye(n_features)\n\n        pi = np.ones(self.n_components) / self.n_components\n\n        return means, cov, pi\n\n    def __repr__(self) -&gt; str:\n        return f\"GMM(n_components={self.n_components})\"\n\n    @staticmethod\n    def estimate_full_covariance(\n        X: np.ndarray,\n        resp: np.ndarray,\n        nk: np.ndarray,\n        means: np.ndarray,\n        reg_covar: float,\n    ) -&gt; np.ndarray:\n        \"\"\"Estimate full covariance matrix\n\n        Shape notation:\n\n                N: number of samples\n                D: number of features\n                K: number of mixture components\n\n        Args:\n            X (numpy.ndarray): Data matrix of shape (N, D)\n            resp (numpy.ndarray): Responsibility matrix of shape (N,K)\n            nk (numpy.ndarray): Total responsibility per cluster of shape (K,)\n            means (numpy.ndarray): Means array of shape (K, D)\n            reg_covar (float): Regularisation added to diagonal of covariance matrix \\\n                to ensure positive definiteness\n\n        Returns:\n            cov (numpy.ndarray): Covariance matrix of shape (K,D,D)\n        \"\"\"\n        n_components, n_features = means.shape\n        cov = np.empty((n_components, n_features, n_features))\n        for k in range(n_components):\n            delta = X - means[k]\n            cov[k] = (\n                np.dot(resp[:, k] * delta.T, delta) / nk[k]\n                + np.eye(n_features) * reg_covar\n            )\n        return cov\n\n    @staticmethod\n    def estimate_tied_covariance(\n        X: np.ndarray,\n        resp: np.ndarray,\n        nk: np.ndarray,\n        means: np.ndarray,\n        reg_covar: float,\n    ) -&gt; np.ndarray:\n        \"\"\"Estimate tied covariance matrix\n\n        Shape notation:\n\n                N: number of samples\n                D: number of features\n                K: number of mixture components\n\n        Args:\n            X (numpy.ndarray): Data matrix of shape (N, D)\n            resp (numpy.ndarray): Responsibility matrix of shape (N,K)\n            nk (numpy.ndarray): Total responsibility per cluster of shape (K,)\n            means (numpy.ndarray): Means array of shape (K, D)\n            reg_covar (float): Regularisation added to diagonal of covariance matrix \\\n                to ensure positive definiteness\n\n        Returns:\n            cov (numpy.ndarray): Covariance matrix of shape (K,D,D)\n        \"\"\"\n        n_components, n_features = means.shape\n        avg_X2 = np.dot(X.T, X)\n        avg_means2 = np.dot(nk * means.T, means)\n        cov = (avg_X2 - avg_means2) / nk.sum() + np.eye(n_features) * reg_covar\n\n        # Convert (D,D) cov to (K,D,D) cov where all K cov matrices are equal\n        cov = np.repeat(cov[np.newaxis], n_components, axis=0)\n        return cov\n\n    def e_step(\n        self,\n        X: np.ndarray,\n        resp: np.ndarray,\n        means: np.ndarray,\n        cov: np.ndarray,\n        pi: np.ndarray,\n        sample_inds: ArrayLike,\n    ) -&gt; tuple[np.ndarray, np.ndarray]:\n        \"\"\"Expectation step\n\n        Shape notation:\n\n            N: number of samples\n            D: number of features\n            K: number of mixture components\n\n        Args:\n            X (numpy.ndarray): Data matrix of shape (N, D)\n            resp (numpy.ndarray): Responsibility matrix of shape (N,K)\n            means (numpy.ndarray): Means array of shape (K, D)\n            cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - full\n            pi (numpy.ndarray): Mixture weights of shape (K,)\n            sample_inds (ArrayLike): Samples to be considered\n\n        Returns:\n            tuple:\n                - resp (numpy.ndarray): Responsibility matrix of shape (N,K)\n                - wpdf (numpy.ndarray): Unnormalised responsibility matrix of shape (N,K)\n        \"\"\"\n        for k in range(self.n_components):\n            resp[sample_inds, k] = pi[k] * multivariate_normal.pdf(\n                X[sample_inds], means[k], cov[k]\n            )\n        wpdf = resp.copy()  # For log likelihood computation\n        # Safe normalisation\n        a = np.sum(resp, axis=1, keepdims=True)\n        idx = np.where(a == 0)[0]\n        a[idx] = 1.0\n        resp = resp / a\n        return resp, wpdf\n\n    def m_step(\n        self, X: np.ndarray, resp: np.ndarray\n    ) -&gt; tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"Maximisation step\n\n        Shape notation:\n\n            N: number of samples\n            D: number of features\n            K: number of mixture components\n\n        Args:\n            X (numpy.ndarray): Data matrix of shape (N, D)\n            resp (numpy.ndarray): Responsibility matrix of shape (N,K)\n\n        Returns:\n            tuple:\n                - means (numpy.ndarray): Means array of shape (K, D)\n                - cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - full\n                - pi (numpy.ndarray): Mixture weights of shape (K,)\n        \"\"\"\n        # M step\n        n_samples, _ = X.shape\n        nk = resp.sum(axis=0)\n        means = np.dot(resp.T, X) / nk[:, np.newaxis]\n        pi = nk / n_samples\n\n        if self.cov_type == \"tied\":\n            cov = self.estimate_tied_covariance(X, resp, nk, means, self.reg_covar)\n        else:\n            cov = self.estimate_full_covariance(X, resp, nk, means, self.reg_covar)\n\n        return means, pi, cov\n\n    def fit(\n        self,\n        X: np.ndarray,\n        resp: Optional[np.ndarray] = None,\n        sample_inds: Optional[ArrayLike] = None,\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Fit a GMM to X with initial responsibility resp. If sample_inds are specified, only those\n        indexes are considered.\n\n\n        Args:\n            X (numpy.ndarray): Data matrix\n            resp (numpy.ndarray, optional): Initial responsibility matrix. Defaults to None.\n            sample_inds (ArrayLike, optional): Sample indexes to be considered. Defaults to None.\n\n        Returns:\n            resp (numpy.ndarray): Responsibility matrix\n        \"\"\"\n\n        n_samples, _ = X.shape\n\n        if sample_inds is None:\n            sample_inds = range(n_samples)\n\n        means, cov, pi = self.init_cluster_params(X)\n        lls = []\n\n        if resp is None:\n            resp = np.random.rand(n_samples, self.n_components)\n            resp /= resp.sum(axis=1, keepdims=True)\n        else:\n            means, pi, cov = self.m_step(X, resp)\n\n        # EM algorithm\n        for i in range(self.niter):\n            # resp_old = resp + 0.0\n\n            # E step\n            resp, wpdf = self.e_step(X, resp, means, cov, pi, sample_inds)\n            # M step\n            means, pi, cov = self.m_step(X, resp)\n\n            # resp_flat = resp.ravel()\n            # resp_old_flat = resp_old.ravel()\n            # idx = np.where(resp.flat)[0]\n            # ll = np.sum(resp_old_flat[idx] * np.log(resp_flat[idx]))\n            ll = np.log(wpdf.sum(axis=1)).sum()\n            lls.append(ll)\n\n            # print(f\"Log-likelihood:{ll}\")\n            if i &gt; 1 and np.abs(lls[i] - lls[i - 1]) &lt; self.tol:\n                # print(\"Exiting\")\n                break\n\n        return resp, means, cov, pi\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.GMM.e_step","title":"<code>e_step(X, resp, means, cov, pi, sample_inds)</code>","text":"<p>Expectation step</p> <p>Shape notation:</p> <pre><code>N: number of samples\nD: number of features\nK: number of mixture components\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix of shape (N, D)</p> required <code>resp</code> <code>ndarray</code> <p>Responsibility matrix of shape (N,K)</p> required <code>means</code> <code>ndarray</code> <p>Means array of shape (K, D)</p> required <code>cov</code> <code>ndarray</code> <p>Covariance matrix of shape (K,D,D) - full</p> required <code>pi</code> <code>ndarray</code> <p>Mixture weights of shape (K,)</p> required <code>sample_inds</code> <code>ArrayLike</code> <p>Samples to be considered</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[ndarray, ndarray]</code> <ul> <li>resp (numpy.ndarray): Responsibility matrix of shape (N,K)</li> <li>wpdf (numpy.ndarray): Unnormalised responsibility matrix of shape (N,K)</li> </ul> Source code in <code>changedet/utils.py</code> <pre><code>def e_step(\n    self,\n    X: np.ndarray,\n    resp: np.ndarray,\n    means: np.ndarray,\n    cov: np.ndarray,\n    pi: np.ndarray,\n    sample_inds: ArrayLike,\n) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Expectation step\n\n    Shape notation:\n\n        N: number of samples\n        D: number of features\n        K: number of mixture components\n\n    Args:\n        X (numpy.ndarray): Data matrix of shape (N, D)\n        resp (numpy.ndarray): Responsibility matrix of shape (N,K)\n        means (numpy.ndarray): Means array of shape (K, D)\n        cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - full\n        pi (numpy.ndarray): Mixture weights of shape (K,)\n        sample_inds (ArrayLike): Samples to be considered\n\n    Returns:\n        tuple:\n            - resp (numpy.ndarray): Responsibility matrix of shape (N,K)\n            - wpdf (numpy.ndarray): Unnormalised responsibility matrix of shape (N,K)\n    \"\"\"\n    for k in range(self.n_components):\n        resp[sample_inds, k] = pi[k] * multivariate_normal.pdf(\n            X[sample_inds], means[k], cov[k]\n        )\n    wpdf = resp.copy()  # For log likelihood computation\n    # Safe normalisation\n    a = np.sum(resp, axis=1, keepdims=True)\n    idx = np.where(a == 0)[0]\n    a[idx] = 1.0\n    resp = resp / a\n    return resp, wpdf\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.GMM.estimate_full_covariance","title":"<code>estimate_full_covariance(X, resp, nk, means, reg_covar)</code>  <code>staticmethod</code>","text":"<p>Estimate full covariance matrix</p> <p>Shape notation:</p> <pre><code>    N: number of samples\n    D: number of features\n    K: number of mixture components\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix of shape (N, D)</p> required <code>resp</code> <code>ndarray</code> <p>Responsibility matrix of shape (N,K)</p> required <code>nk</code> <code>ndarray</code> <p>Total responsibility per cluster of shape (K,)</p> required <code>means</code> <code>ndarray</code> <p>Means array of shape (K, D)</p> required <code>reg_covar</code> <code>float</code> <p>Regularisation added to diagonal of covariance matrix                 to ensure positive definiteness</p> required <p>Returns:</p> Name Type Description <code>cov</code> <code>ndarray</code> <p>Covariance matrix of shape (K,D,D)</p> Source code in <code>changedet/utils.py</code> <pre><code>@staticmethod\ndef estimate_full_covariance(\n    X: np.ndarray,\n    resp: np.ndarray,\n    nk: np.ndarray,\n    means: np.ndarray,\n    reg_covar: float,\n) -&gt; np.ndarray:\n    \"\"\"Estimate full covariance matrix\n\n    Shape notation:\n\n            N: number of samples\n            D: number of features\n            K: number of mixture components\n\n    Args:\n        X (numpy.ndarray): Data matrix of shape (N, D)\n        resp (numpy.ndarray): Responsibility matrix of shape (N,K)\n        nk (numpy.ndarray): Total responsibility per cluster of shape (K,)\n        means (numpy.ndarray): Means array of shape (K, D)\n        reg_covar (float): Regularisation added to diagonal of covariance matrix \\\n            to ensure positive definiteness\n\n    Returns:\n        cov (numpy.ndarray): Covariance matrix of shape (K,D,D)\n    \"\"\"\n    n_components, n_features = means.shape\n    cov = np.empty((n_components, n_features, n_features))\n    for k in range(n_components):\n        delta = X - means[k]\n        cov[k] = (\n            np.dot(resp[:, k] * delta.T, delta) / nk[k]\n            + np.eye(n_features) * reg_covar\n        )\n    return cov\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.GMM.estimate_tied_covariance","title":"<code>estimate_tied_covariance(X, resp, nk, means, reg_covar)</code>  <code>staticmethod</code>","text":"<p>Estimate tied covariance matrix</p> <p>Shape notation:</p> <pre><code>    N: number of samples\n    D: number of features\n    K: number of mixture components\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix of shape (N, D)</p> required <code>resp</code> <code>ndarray</code> <p>Responsibility matrix of shape (N,K)</p> required <code>nk</code> <code>ndarray</code> <p>Total responsibility per cluster of shape (K,)</p> required <code>means</code> <code>ndarray</code> <p>Means array of shape (K, D)</p> required <code>reg_covar</code> <code>float</code> <p>Regularisation added to diagonal of covariance matrix                 to ensure positive definiteness</p> required <p>Returns:</p> Name Type Description <code>cov</code> <code>ndarray</code> <p>Covariance matrix of shape (K,D,D)</p> Source code in <code>changedet/utils.py</code> <pre><code>@staticmethod\ndef estimate_tied_covariance(\n    X: np.ndarray,\n    resp: np.ndarray,\n    nk: np.ndarray,\n    means: np.ndarray,\n    reg_covar: float,\n) -&gt; np.ndarray:\n    \"\"\"Estimate tied covariance matrix\n\n    Shape notation:\n\n            N: number of samples\n            D: number of features\n            K: number of mixture components\n\n    Args:\n        X (numpy.ndarray): Data matrix of shape (N, D)\n        resp (numpy.ndarray): Responsibility matrix of shape (N,K)\n        nk (numpy.ndarray): Total responsibility per cluster of shape (K,)\n        means (numpy.ndarray): Means array of shape (K, D)\n        reg_covar (float): Regularisation added to diagonal of covariance matrix \\\n            to ensure positive definiteness\n\n    Returns:\n        cov (numpy.ndarray): Covariance matrix of shape (K,D,D)\n    \"\"\"\n    n_components, n_features = means.shape\n    avg_X2 = np.dot(X.T, X)\n    avg_means2 = np.dot(nk * means.T, means)\n    cov = (avg_X2 - avg_means2) / nk.sum() + np.eye(n_features) * reg_covar\n\n    # Convert (D,D) cov to (K,D,D) cov where all K cov matrices are equal\n    cov = np.repeat(cov[np.newaxis], n_components, axis=0)\n    return cov\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.GMM.fit","title":"<code>fit(X, resp=None, sample_inds=None)</code>","text":"<p>Fit a GMM to X with initial responsibility resp. If sample_inds are specified, only those indexes are considered.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix</p> required <code>resp</code> <code>ndarray</code> <p>Initial responsibility matrix. Defaults to None.</p> <code>None</code> <code>sample_inds</code> <code>ArrayLike</code> <p>Sample indexes to be considered. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>resp</code> <code>ndarray</code> <p>Responsibility matrix</p> Source code in <code>changedet/utils.py</code> <pre><code>def fit(\n    self,\n    X: np.ndarray,\n    resp: Optional[np.ndarray] = None,\n    sample_inds: Optional[ArrayLike] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Fit a GMM to X with initial responsibility resp. If sample_inds are specified, only those\n    indexes are considered.\n\n\n    Args:\n        X (numpy.ndarray): Data matrix\n        resp (numpy.ndarray, optional): Initial responsibility matrix. Defaults to None.\n        sample_inds (ArrayLike, optional): Sample indexes to be considered. Defaults to None.\n\n    Returns:\n        resp (numpy.ndarray): Responsibility matrix\n    \"\"\"\n\n    n_samples, _ = X.shape\n\n    if sample_inds is None:\n        sample_inds = range(n_samples)\n\n    means, cov, pi = self.init_cluster_params(X)\n    lls = []\n\n    if resp is None:\n        resp = np.random.rand(n_samples, self.n_components)\n        resp /= resp.sum(axis=1, keepdims=True)\n    else:\n        means, pi, cov = self.m_step(X, resp)\n\n    # EM algorithm\n    for i in range(self.niter):\n        # resp_old = resp + 0.0\n\n        # E step\n        resp, wpdf = self.e_step(X, resp, means, cov, pi, sample_inds)\n        # M step\n        means, pi, cov = self.m_step(X, resp)\n\n        # resp_flat = resp.ravel()\n        # resp_old_flat = resp_old.ravel()\n        # idx = np.where(resp.flat)[0]\n        # ll = np.sum(resp_old_flat[idx] * np.log(resp_flat[idx]))\n        ll = np.log(wpdf.sum(axis=1)).sum()\n        lls.append(ll)\n\n        # print(f\"Log-likelihood:{ll}\")\n        if i &gt; 1 and np.abs(lls[i] - lls[i - 1]) &lt; self.tol:\n            # print(\"Exiting\")\n            break\n\n    return resp, means, cov, pi\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.GMM.init_cluster_params","title":"<code>init_cluster_params(X)</code>","text":"<p>Initialse cluster parameters</p> <p>Shape notation:</p> <pre><code>N: number of samples\nD: number of features\nK: number of mixture components\n</code></pre> <p>Initialisation method:</p> <pre><code>Initialise means to a random data point in X\nInitialse cov to a spherical covariance matrix of variance 1\nInitialse pi to uniform distribution\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix of shape (N,D)</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[ndarray, ndarray, ndarray]</code> <ul> <li>means (numpy.ndarray): Means array of shape (K, D)</li> <li>cov (numpy.ndarray): Covariance matrix of shape (K,D,D)</li> <li>pi (numpy.ndarray): Mixture weights of shape (K,)</li> </ul> Source code in <code>changedet/utils.py</code> <pre><code>def init_cluster_params(\n    self, X: np.ndarray\n) -&gt; tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Initialse cluster parameters\n\n    Shape notation:\n\n        N: number of samples\n        D: number of features\n        K: number of mixture components\n\n    Initialisation method:\n\n        Initialise means to a random data point in X\n        Initialse cov to a spherical covariance matrix of variance 1\n        Initialse pi to uniform distribution\n\n    Args:\n        X (numpy.ndarray): Data matrix of shape (N,D)\n\n    Returns:\n        tuple:\n            - means (numpy.ndarray): Means array of shape (K, D)\n            - cov (numpy.ndarray): Covariance matrix of shape (K,D,D)\n            - pi (numpy.ndarray): Mixture weights of shape (K,)\n    \"\"\"\n\n    n_samples, n_features = X.shape\n    means = np.zeros((self.n_components, n_features))\n    cov = np.zeros((self.n_components, n_features, n_features))\n\n    # Initialise\n    # Mean -&gt; random data point\n    # Cov -&gt; spherical covariance - all clusters have same diagonal cov\n    # matrix and diagonal elements are all equal\n    for k in range(self.n_components):\n        means[k] = X[np.random.choice(n_samples)]\n        cov[k] = np.eye(n_features)\n\n    pi = np.ones(self.n_components) / self.n_components\n\n    return means, cov, pi\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.GMM.m_step","title":"<code>m_step(X, resp)</code>","text":"<p>Maximisation step</p> <p>Shape notation:</p> <pre><code>N: number of samples\nD: number of features\nK: number of mixture components\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix of shape (N, D)</p> required <code>resp</code> <code>ndarray</code> <p>Responsibility matrix of shape (N,K)</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[ndarray, ndarray, ndarray]</code> <ul> <li>means (numpy.ndarray): Means array of shape (K, D)</li> <li>cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - full</li> <li>pi (numpy.ndarray): Mixture weights of shape (K,)</li> </ul> Source code in <code>changedet/utils.py</code> <pre><code>def m_step(\n    self, X: np.ndarray, resp: np.ndarray\n) -&gt; tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Maximisation step\n\n    Shape notation:\n\n        N: number of samples\n        D: number of features\n        K: number of mixture components\n\n    Args:\n        X (numpy.ndarray): Data matrix of shape (N, D)\n        resp (numpy.ndarray): Responsibility matrix of shape (N,K)\n\n    Returns:\n        tuple:\n            - means (numpy.ndarray): Means array of shape (K, D)\n            - cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - full\n            - pi (numpy.ndarray): Mixture weights of shape (K,)\n    \"\"\"\n    # M step\n    n_samples, _ = X.shape\n    nk = resp.sum(axis=0)\n    means = np.dot(resp.T, X) / nk[:, np.newaxis]\n    pi = nk / n_samples\n\n    if self.cov_type == \"tied\":\n        cov = self.estimate_tied_covariance(X, resp, nk, means, self.reg_covar)\n    else:\n        cov = self.estimate_full_covariance(X, resp, nk, means, self.reg_covar)\n\n    return means, pi, cov\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.InitialChangeMask","title":"<code>InitialChangeMask</code>","text":"<p>Initial Change Mask</p> <p>Create a change mask to remove strong changes and enable better radiometric normalisation.</p>"},{"location":"reference/utils.html#changedet.utils.InitialChangeMask--references","title":"References","text":"<ul> <li>P. R. Marpu, P. Gamba and M. J. Canty, \"Improving Change Detection Results   of IR-MAD by Eliminating Strong Changes,\" in IEEE Geoscience and Remote   Sensing Letters, vol. 8 no. 4, pp. 799-803, July 2011,   doi:10.1109/LGRS.2011.2109697.</li> </ul> Source code in <code>changedet/utils.py</code> <pre><code>class InitialChangeMask:  # pragma: no cover\n    \"\"\"Initial Change Mask\n\n    Create a change mask to remove strong changes and enable better radiometric\n    normalisation.\n\n\n    References\n    ----------\n    - P. R. Marpu, P. Gamba and M. J. Canty, \"Improving Change Detection Results\n      of IR-MAD by Eliminating Strong Changes,\" in IEEE Geoscience and Remote\n      Sensing Letters, vol. 8 no. 4, pp. 799-803, July 2011,\n      doi:10.1109/LGRS.2011.2109697.\n    \"\"\"\n\n    def __init__(self, mode: str = \"hist\") -&gt; None:\n        self.mode = mode\n        self.gmm = GMM(3, cov_type=\"full\")\n\n    @staticmethod\n    def plot(mean: np.ndarray, cov: np.ndarray, thresh: float) -&gt; None:\n\n        sigma = np.sqrt(cov)\n        mix_names = [\"No change\", \"Ambiguous\", \"Pure Change\"]\n        mix_colours = [\"r\", \"g\", \"b\"]\n        # f1 = plt.figure()\n        for m, sig, name, colour in zip(mean, sigma, mix_names, mix_colours):\n            p = np.linspace(m - 3 * sig, m + 3 * sig, 100)\n            plt.plot(p, norm.pdf(p, m, sig), label=name, color=colour)\n        plt.legend()\n        plt.tight_layout()\n        plt.margins(0)\n        plt.axvline(x=thresh, color=\"k\", linestyle=\"--\")\n        plt.show()\n\n    def prepare(self, im1: np.ndarray, im2: np.ndarray, plot: bool = True) -&gt; np.ndarray:\n        # Linear stretch\n        im1 = contrast_stretch(im1, stretch_type=\"percentile\")\n        im2 = contrast_stretch(im2, stretch_type=\"percentile\")\n\n        ch1, r1, c1 = im1.shape\n\n        m = r1 * c1\n        N = ch1\n\n        im1r = im1.reshape(N, m).T\n        im2r = im2.reshape(N, m).T\n\n        diff = np.abs(im1r - im2r)\n        # Max difference\n        diff = diff.max(axis=1)[:, np.newaxis]\n\n        _, mean, cov, pi = self.gmm.fit(diff)\n\n        mean = mean.flatten()\n        cov = cov.flatten()\n        pi = pi.flatten()\n\n        # Sort in ascending order\n        idx = np.argsort(mean)\n        mean = mean[idx]\n        cov = cov[idx]\n        pi = pi[idx]\n\n        # Refer https://gist.github.com/ashnair1/433ffbc1e747f80067f8a0439e346279\n        # for derivation of the equation\n\n        # TODO: Computing roots via this method results in invalid thresholds.\n        # In theory, this and the current method should yield same results.\n\n        # k = np.log((np.sqrt(cov[0]) * pi[1]) / (np.sqrt(cov[1]) * pi[0]))\n        # a = cov[1] - cov[0]\n        # b = -2 * (mean[0] * cov[1] - mean[1] * cov[0])\n        # c = mean[0] ** 2 * cov[1] - mean[1] ** 2 * cov[0] + 2 * k * (cov[0] * cov[1])\n        # roots = np.roots([a, b, c])\n\n        roots = self.roots(mean, cov, pi)\n\n        m1 = mean[0]\n        m2 = mean[1]\n        s1 = roots[0]\n        s2 = roots[1]\n\n        thresh = (\n            ((m1 &gt; m2) * (m1 &gt; s1) * (m2 &lt; s1) * s1)\n            + ((m1 &gt; m2) * (m1 &gt; s2) * (m2 &lt; s2) * s2)\n            + ((m2 &gt; m1) * (m2 &gt; s1) * (m1 &lt; s1) * s1)\n            + ((m2 &gt; m1) * (m2 &gt; s2) * (m1 &lt; s2) * s2)\n        )\n\n        # Plot distributions and threshold\n        if plot:\n            self.plot(mean, cov, thresh)\n\n        if not thresh:\n            return None\n\n        icm = np.where(diff &lt; thresh, 0, 1)\n        icm = icm.reshape(r1, c1)\n        return icm\n\n    @staticmethod\n    def roots(mean: np.ndarray, var: np.ndarray, pi: np.ndarray) -&gt; tuple[float, float]:\n        \"\"\"Compute the threshold between the no-change and change distributions\n        from the mean, variance and mixture weight (pi) of no change, change and\n        ambigous distributions.\n\n        Refer this [gist](&lt;https://gist.github.com/ashnair1/433ffbc1e747f80067f8a0439e346279&gt;)\n        for full derivation.\n\n        Args:\n            mean (np.ndarray): means of distributions\n            var (np.ndarray): variances of distributions\n            pi (np.ndarray): mixture weights\n\n        Returns:\n            Tuple[float, float]: thresholds\n        \"\"\"\n        std1 = np.sqrt(var[0])\n        std2 = np.sqrt(var[1])\n        k = np.log((std1 * pi[1]) / (std2 * pi[0]))\n        n1 = var[1] * mean[0] - var[0] * mean[1]\n        n2 = np.sqrt(\n            var[0] * var[1] * (mean[0] - mean[1]) ** 2 + 0.5 * k * (var[0] - var[1])\n        )\n        d1 = var[1] - var[0]\n        root1 = (n1 + n2) / d1\n        root2 = (n1 - n2) / d1\n        return root1, root2\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.InitialChangeMask.roots","title":"<code>roots(mean, var, pi)</code>  <code>staticmethod</code>","text":"<p>Compute the threshold between the no-change and change distributions from the mean, variance and mixture weight (pi) of no change, change and ambigous distributions.</p> <p>Refer this gist for full derivation.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>ndarray</code> <p>means of distributions</p> required <code>var</code> <code>ndarray</code> <p>variances of distributions</p> required <code>pi</code> <code>ndarray</code> <p>mixture weights</p> required <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple[float, float]: thresholds</p> Source code in <code>changedet/utils.py</code> <pre><code>@staticmethod\ndef roots(mean: np.ndarray, var: np.ndarray, pi: np.ndarray) -&gt; tuple[float, float]:\n    \"\"\"Compute the threshold between the no-change and change distributions\n    from the mean, variance and mixture weight (pi) of no change, change and\n    ambigous distributions.\n\n    Refer this [gist](&lt;https://gist.github.com/ashnair1/433ffbc1e747f80067f8a0439e346279&gt;)\n    for full derivation.\n\n    Args:\n        mean (np.ndarray): means of distributions\n        var (np.ndarray): variances of distributions\n        pi (np.ndarray): mixture weights\n\n    Returns:\n        Tuple[float, float]: thresholds\n    \"\"\"\n    std1 = np.sqrt(var[0])\n    std2 = np.sqrt(var[1])\n    k = np.log((std1 * pi[1]) / (std2 * pi[0]))\n    n1 = var[1] * mean[0] - var[0] * mean[1]\n    n2 = np.sqrt(\n        var[0] * var[1] * (mean[0] - mean[1]) ** 2 + 0.5 * k * (var[0] - var[1])\n    )\n    d1 = var[1] - var[0]\n    root1 = (n1 + n2) / d1\n    root2 = (n1 - n2) / d1\n    return root1, root2\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.check_pos_semi_def","title":"<code>check_pos_semi_def(mat)</code>","text":"<p>Test whether matrix is positive semi-definite</p> <p>Ref:</p> <ul> <li>https://scicomp.stackexchange.com/a/12984/39306</li> <li>https://stackoverflow.com/a/63911811/10800115</li> </ul> <p>Parameters:</p> Name Type Description Default <code>mat</code> <code>ndarray</code> <p>Input matrix</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if mat is positive semi-definite else False</p> Source code in <code>changedet/utils.py</code> <pre><code>def check_pos_semi_def(mat: np.ndarray) -&gt; bool:\n    \"\"\"Test whether matrix is positive semi-definite\n\n    Ref:\n\n    - &lt;https://scicomp.stackexchange.com/a/12984/39306&gt;\n    - &lt;https://stackoverflow.com/a/63911811/10800115&gt;\n\n    Args:\n        mat (np.ndarray): Input matrix\n\n    Returns:\n        bool: True if mat is positive semi-definite else False\n    \"\"\"\n\n    try:\n        reg_mat = mat + np.eye(mat.shape[0]) * 1e-3\n        np.linalg.cholesky(reg_mat)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.contrast_stretch","title":"<code>contrast_stretch(img, *, target_type='uint8', stretch_type='minmax', percentile=(2, 98))</code>","text":"<p>Change image distribution to cover full range of target_type.</p> <p>Types of contrast stretching: - minmax (Default) - percentile</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>ndarray</code> <p>Input image</p> required <code>target_type</code> <code>dtype</code> <p>Target type of rescaled image. Defaults to \"uint8\".</p> <code>'uint8'</code> <code>stretch_type</code> <code>str</code> <p>Types of contrast stretching. Defaults to \"minmax\".</p> <code>'minmax'</code> <code>percentile</code> <code>tuple</code> <p>Cut off percentiles if stretch_type = \"percentile\". Defaults to (2, 98).</p> <code>(2, 98)</code> <p>Returns:</p> Name Type Description <code>scaled</code> <code>ndarray</code> <p>Rescaled image</p> Source code in <code>changedet/utils.py</code> <pre><code>def contrast_stretch(\n    img: np.ndarray,\n    *,\n    target_type: str = \"uint8\",\n    stretch_type: str = \"minmax\",\n    percentile: tuple[int, int] = (2, 98),\n) -&gt; np.ndarray:\n    \"\"\"Change image distribution to cover full range of target_type.\n\n    Types of contrast stretching:\n    - minmax (Default)\n    - percentile\n\n    Args:\n        img (numpy.ndarray): Input image\n        target_type (dtype): Target type of rescaled image. Defaults to \"uint8\".\n        stretch_type (str): Types of contrast stretching. Defaults to \"minmax\".\n        percentile (tuple): Cut off percentiles if stretch_type = \"percentile\". Defaults to (2, 98).\n\n    Returns:\n        scaled (numpy.ndarray): Rescaled image\n    \"\"\"\n\n    type_info = np.iinfo(target_type)\n    minout = type_info.min\n    maxout = type_info.max\n\n    if stretch_type == \"percentile\":\n        lower, upper = np.nanpercentile(img, percentile)\n    else:\n        lower = np.min(img)\n        upper = np.max(img)\n\n    # Contrast Stretching\n    a = (maxout - minout) / (upper - lower)\n    b = minout - a * lower\n    g = a * img + b\n    return np.clip(g, minout, maxout)\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.histplot","title":"<code>histplot(xlist, xlabel, bins=50)</code>","text":"<p>Plot multiple histograms in the same figure</p> <p>Parameters:</p> Name Type Description Default <code>xlist</code> <code>arraylike</code> <p>Sequence</p> required <code>xlabel</code> <code>list[str]</code> <p>Sequence label</p> required <code>bins</code> <code>int</code> <p>Histogram bins. Defaults to 50.</p> <code>50</code> <p>Returns:</p> Type Description <code>Figure</code> <p>matplotlib.figure.figure: Figure with histograms</p> Source code in <code>changedet/utils.py</code> <pre><code>def histplot(xlist: ArrayLike, xlabel: list[str], bins: Optional[int] = 50) -&gt; Figure:\n    \"\"\"Plot multiple histograms in the same figure\n\n    Args:\n        xlist (arraylike): Sequence\n        xlabel (list[str]): Sequence label\n        bins (int, optional): Histogram bins. Defaults to 50.\n\n    Returns:\n        matplotlib.figure.figure: Figure with histograms\n    \"\"\"\n    f = plt.figure()\n    for i, j in zip(xlist, xlabel):\n        plt.hist(i[:, :, 0].flatten(), bins=bins, label=j)\n    plt.legend()\n    return f\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.init_logger","title":"<code>init_logger(name='logger', output=None)</code>","text":"<p>Initialise changedet logger</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of this logger. Defaults to \"logger\".</p> <code>'logger'</code> <code>output</code> <code>str</code> <p>Path to folder/file to write logs. If None, logs are not written</p> <code>None</code> Source code in <code>changedet/utils.py</code> <pre><code>def init_logger(name: str = \"logger\", output: Optional[str] = None) -&gt; logging.Logger:\n    \"\"\"\n    Initialise changedet logger\n\n    Args:\n        name (str, optional): Name of this logger. Defaults to \"logger\".\n        output (str, optional): Path to folder/file to write logs. If None, logs are not written\n    \"\"\"\n    logger = logging.getLogger(name=name)\n    logger.setLevel(logging.DEBUG)\n\n    # Output logs to terminal\n    streamhandler = logging.StreamHandler(sys.stdout)\n    streamhandler.setLevel(logging.INFO)\n    streamhandler.setFormatter(_ColorFormatter(datefmt=\"%Y-%m-%d %H:%M:%S\"))\n    logger.addHandler(streamhandler)\n\n    # Output logs to file\n    if output:\n        output_path = Path(output)\n        logfile = (\n            output_path\n            if output_path.suffix in [\".txt\", \".log\"]\n            else output_path / \"log.txt\"\n        )\n        Path.mkdir(output_path.parent)\n\n        filehandler = logging.FileHandler(logfile)\n        filehandler.setLevel(logging.DEBUG)\n        filehandler.setFormatter(_ColorFormatter(datefmt=\"%Y-%m-%d %H:%M:%S\"))\n        logger.addHandler(filehandler)\n    return logger\n</code></pre>"},{"location":"reference/utils.html#changedet.utils.np_weight_stats","title":"<code>np_weight_stats(x, ws=None)</code>","text":"<p>Calculate weighted mean and sample covariance.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Data matrix of shape (N,D)</p> required <code>ws</code> <code>ndarray</code> <p>Weight vector of shape (N,). Defaults to None</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[ndarray, ndarray]</code> <ul> <li>wsigma (numpy.ndarray): Weighted covariance matrix</li> <li>wmean (numpy.ndarray): Weighted mean</li> </ul> Source code in <code>changedet/utils.py</code> <pre><code>def np_weight_stats(\n    x: np.ndarray, ws: Optional[np.ndarray] = None\n) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Calculate weighted mean and sample covariance.\n\n    Args:\n        x (numpy.ndarray): Data matrix of shape (N,D)\n        ws (numpy.ndarray, optional): Weight vector of shape (N,). Defaults to None\n\n    Returns:\n        tuple:\n            - wsigma (numpy.ndarray): Weighted covariance matrix\n            - wmean (numpy.ndarray): Weighted mean\n    \"\"\"\n    # Uniform weight if ws is unspecified or array of zeros\n    if ws is None or not np.any(ws):\n        ws = np.ones(x.shape[0])\n    mean = np.ma.average(x, axis=0, weights=ws)\n    wmean = np.expand_dims(mean.data, axis=1)  # (H*W,) -&gt; (H*W,1)\n    wsigma = np.cov(x, rowvar=False, aweights=ws)\n    return wsigma, wmean\n</code></pre>"},{"location":"reference/algos/base.html","title":"base","text":""},{"location":"reference/algos/base.html#changedet.algos.base.MetaAlgo","title":"<code>MetaAlgo</code>","text":"<p>Base class for an algorithm</p> Source code in <code>changedet/algos/base.py</code> <pre><code>class MetaAlgo(metaclass=ABCMeta):\n    \"\"\"Base class for an algorithm\"\"\"\n\n    @classmethod\n    @abstractmethod\n    def run(cls, im1: np.ndarray, im2: np.ndarray, **kwargs: Any) -&gt; np.ndarray:\n        \"\"\"\n        Abstract method to run change detection\n\n        Every algorithm will have at least one keyword argument - the global logger\n        \"\"\"\n        assert \"logger\" in kwargs\n</code></pre>"},{"location":"reference/algos/base.html#changedet.algos.base.MetaAlgo.run","title":"<code>run(im1, im2, **kwargs)</code>  <code>abstractmethod</code> <code>classmethod</code>","text":"<p>Abstract method to run change detection</p> <p>Every algorithm will have at least one keyword argument - the global logger</p> Source code in <code>changedet/algos/base.py</code> <pre><code>@classmethod\n@abstractmethod\ndef run(cls, im1: np.ndarray, im2: np.ndarray, **kwargs: Any) -&gt; np.ndarray:\n    \"\"\"\n    Abstract method to run change detection\n\n    Every algorithm will have at least one keyword argument - the global logger\n    \"\"\"\n    assert \"logger\" in kwargs\n</code></pre>"},{"location":"reference/algos/catalog.html","title":"catalog","text":""},{"location":"reference/algos/catalog.html#changedet.algos.catalog.AlgoCatalog_","title":"<code>AlgoCatalog_</code>","text":"<p>             Bases: <code>_Base</code></p> <p>A global dictionary that stores information about the algorithms used and their corresponding pipeline. It contains a mapping of algorithm names to the algorithm class object.</p> <pre><code>&gt;&gt;&gt; from changedet.algos import AlgoCatalog\n&gt;&gt;&gt; import pprint\n&gt;&gt;&gt; pprint.pprint(AlgoCatalog)\n{'cva': &lt;class 'changedet.algos.cva.CVA'&gt;,\n 'imgdiff': &lt;class 'changedet.algos.imgdiff.ImageDiff'&gt;,\n 'ipca': &lt;class 'changedet.algos.ipca.IteratedPCA'&gt;,\n 'irmad': &lt;class 'changedet.algos.irmad.IRMAD'&gt;}\n</code></pre> Source code in <code>changedet/algos/catalog.py</code> <pre><code>class AlgoCatalog_(_Base):\n    \"\"\"\n\n    A global dictionary that stores information about the algorithms used and\n    their corresponding pipeline. It contains a mapping of algorithm names to\n    the algorithm class object.\n\n    ```\n    &gt;&gt;&gt; from changedet.algos import AlgoCatalog\n    &gt;&gt;&gt; import pprint\n    &gt;&gt;&gt; pprint.pprint(AlgoCatalog)\n    {'cva': &lt;class 'changedet.algos.cva.CVA'&gt;,\n     'imgdiff': &lt;class 'changedet.algos.imgdiff.ImageDiff'&gt;,\n     'ipca': &lt;class 'changedet.algos.ipca.IteratedPCA'&gt;,\n     'irmad': &lt;class 'changedet.algos.irmad.IRMAD'&gt;}\n    ```\n\n\n    \"\"\"\n\n    def register(self, name: str) -&gt; Callable[[type[MetaAlgo]], type[MetaAlgo]]:\n        def inner_wrapper(wrapped_class: type[MetaAlgo]) -&gt; type[MetaAlgo]:\n            if name in self.keys():\n                raise AssertionError(f\"Algorithm {name} already exists.\")\n            self[name] = wrapped_class\n            return wrapped_class\n\n        return inner_wrapper\n\n    def get(self, name: str) -&gt; type[MetaAlgo]:  # type: ignore[override]\n        try:\n            f = self[name]\n        except KeyError as e:\n            if isinstance(name, str):\n                avail_algos = \", \".join(list(self.keys()))\n                raise KeyError(\n                    f\"Algorithm {name} is not registered. Available algorithms are: {avail_algos}\"\n                ) from e\n            else:\n                f = None\n        return f\n\n    def list(self) -&gt; list[str]:\n        \"\"\"List all registered algorithms.\n\n        Returns:\n            list[str]: List of algorithm names\n        \"\"\"\n        return list(sorted(self.keys()))\n\n    def remove(self, name: str) -&gt; None:\n        \"\"\"\n        Alias of ``pop``.\n        \"\"\"\n        self.pop(name)\n</code></pre>"},{"location":"reference/algos/catalog.html#changedet.algos.catalog.AlgoCatalog_.list","title":"<code>list()</code>","text":"<p>List all registered algorithms.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: List of algorithm names</p> Source code in <code>changedet/algos/catalog.py</code> <pre><code>def list(self) -&gt; list[str]:\n    \"\"\"List all registered algorithms.\n\n    Returns:\n        list[str]: List of algorithm names\n    \"\"\"\n    return list(sorted(self.keys()))\n</code></pre>"},{"location":"reference/algos/catalog.html#changedet.algos.catalog.AlgoCatalog_.remove","title":"<code>remove(name)</code>","text":"<p>Alias of <code>pop</code>.</p> Source code in <code>changedet/algos/catalog.py</code> <pre><code>def remove(self, name: str) -&gt; None:\n    \"\"\"\n    Alias of ``pop``.\n    \"\"\"\n    self.pop(name)\n</code></pre>"},{"location":"reference/algos/cva.html","title":"cva","text":""},{"location":"reference/algos/cva.html#changedet.algos.cva.CVA","title":"<code>CVA</code>","text":"<p>             Bases: <code>MetaAlgo</code></p> <p>Calculate change vectors</p> <p>Builds a change map by calculating the amplitude map of the change vectors</p> Source code in <code>changedet/algos/cva.py</code> <pre><code>@AlgoCatalog.register(\"cva\")\nclass CVA(MetaAlgo):\n    \"\"\"\n    Calculate change vectors\n\n    Builds a change map by calculating the amplitude map of the change vectors\n    \"\"\"\n\n    @classmethod\n    def run(cls, im1: np.ndarray, im2: np.ndarray, **flags: Any) -&gt; np.ndarray:\n        \"\"\"Run Image Differencing algorithm\n\n        Args:\n            im1 (np.ndarray): Image 1 array\n            im2 (np.ndarray): Image 2 array\n            **flags (dict): Flags for the algorithm\n        \"\"\"\n        distance = flags.get(\"distance\", \"euclidean\")\n        logger = flags[\"logger\"]\n\n        assert distance in [\"euclidean\", \"manhattan\"]\n\n        # Calculate change vectors\n        logger.info(\"Calculating change vectors\")\n        mag, theta = calc_cvs(im1, im2, distance)\n        bcm = appy_threshold(mag)\n\n        return bcm\n</code></pre>"},{"location":"reference/algos/cva.html#changedet.algos.cva.CVA.run","title":"<code>run(im1, im2, **flags)</code>  <code>classmethod</code>","text":"<p>Run Image Differencing algorithm</p> <p>Parameters:</p> Name Type Description Default <code>im1</code> <code>ndarray</code> <p>Image 1 array</p> required <code>im2</code> <code>ndarray</code> <p>Image 2 array</p> required <code>**flags</code> <code>dict</code> <p>Flags for the algorithm</p> <code>{}</code> Source code in <code>changedet/algos/cva.py</code> <pre><code>@classmethod\ndef run(cls, im1: np.ndarray, im2: np.ndarray, **flags: Any) -&gt; np.ndarray:\n    \"\"\"Run Image Differencing algorithm\n\n    Args:\n        im1 (np.ndarray): Image 1 array\n        im2 (np.ndarray): Image 2 array\n        **flags (dict): Flags for the algorithm\n    \"\"\"\n    distance = flags.get(\"distance\", \"euclidean\")\n    logger = flags[\"logger\"]\n\n    assert distance in [\"euclidean\", \"manhattan\"]\n\n    # Calculate change vectors\n    logger.info(\"Calculating change vectors\")\n    mag, theta = calc_cvs(im1, im2, distance)\n    bcm = appy_threshold(mag)\n\n    return bcm\n</code></pre>"},{"location":"reference/algos/imgdiff.html","title":"imgdiff","text":""},{"location":"reference/algos/imgdiff.html#changedet.algos.imgdiff.ImageDiff","title":"<code>ImageDiff</code>","text":"<p>             Bases: <code>MetaAlgo</code></p> <p>Calculate difference map</p> <p>Builds a change map by calculating the difference between image 1 &amp; image 2</p> Source code in <code>changedet/algos/imgdiff.py</code> <pre><code>@AlgoCatalog.register(\"imgdiff\")\nclass ImageDiff(MetaAlgo):\n    \"\"\"\n    Calculate difference map\n\n    Builds a change map by calculating the difference between image 1 &amp; image 2\n    \"\"\"\n\n    @classmethod\n    def run(cls, im1: np.ndarray, im2: np.ndarray, **flags: Any) -&gt; np.ndarray:\n        \"\"\"Run Image Differencing algorithm\n\n        Args:\n            im1 (np.ndarray): Image 1 array\n            im2 (np.ndarray): Image 2 array\n            **flags (dict): Flags for the algorithm\n        \"\"\"\n        logger = flags[\"logger\"]\n\n        # Calculate difference map\n        logger.info(\"Calculating difference map\")\n        diff = im1 - im2\n\n        return diff\n</code></pre>"},{"location":"reference/algos/imgdiff.html#changedet.algos.imgdiff.ImageDiff.run","title":"<code>run(im1, im2, **flags)</code>  <code>classmethod</code>","text":"<p>Run Image Differencing algorithm</p> <p>Parameters:</p> Name Type Description Default <code>im1</code> <code>ndarray</code> <p>Image 1 array</p> required <code>im2</code> <code>ndarray</code> <p>Image 2 array</p> required <code>**flags</code> <code>dict</code> <p>Flags for the algorithm</p> <code>{}</code> Source code in <code>changedet/algos/imgdiff.py</code> <pre><code>@classmethod\ndef run(cls, im1: np.ndarray, im2: np.ndarray, **flags: Any) -&gt; np.ndarray:\n    \"\"\"Run Image Differencing algorithm\n\n    Args:\n        im1 (np.ndarray): Image 1 array\n        im2 (np.ndarray): Image 2 array\n        **flags (dict): Flags for the algorithm\n    \"\"\"\n    logger = flags[\"logger\"]\n\n    # Calculate difference map\n    logger.info(\"Calculating difference map\")\n    diff = im1 - im2\n\n    return diff\n</code></pre>"},{"location":"reference/algos/ipca.html","title":"ipca","text":""},{"location":"reference/algos/ipca.html#changedet.algos.ipca.IteratedPCA","title":"<code>IteratedPCA</code>","text":"<p>             Bases: <code>MetaAlgo</code></p> <p>Iterated PCA Change Classifier.</p> <p>The number of unchanged pixels usually outnumber changed pixels and since they're highly correlated over time, they should lie along the first principal axis while the changed pixels lie along the second axis. However, since the principal components are calculated from the covariance matrix computed for all pixels, the no-change axis might be poorly defined. Iterated PCA solves this by calculating the principal components iteratively and weighting each pixel by its probability to be no change pixels.</p>"},{"location":"reference/algos/ipca.html#changedet.algos.ipca.IteratedPCA--accepted-flags","title":"Accepted flags","text":"<ul> <li>niter = Number of iterations IPCA should be run</li> </ul>"},{"location":"reference/algos/ipca.html#changedet.algos.ipca.IteratedPCA--references","title":"References","text":"<ul> <li>Wiemker, R. (1997). An iterative spectral-spatial Bayesian labeling approach for unsupervised robust change detection on remotely sensed multispectral imagery. In Proceedings of the 7th International Conference on Computer Analysis of Images and Patterns, volume LCNS 1296, pages 263\u2013370.</li> <li>Canty, M.J. (2019). Image Analysis, Classification, and Change Detection in Remote Sensing: With Algorithms for Python (4th ed.). CRC Press. https://doi.org/10.1201/9780429464348</li> </ul> Source code in <code>changedet/algos/ipca.py</code> <pre><code>@AlgoCatalog.register(\"ipca\")\nclass IteratedPCA(MetaAlgo):\n    \"\"\"Iterated PCA Change Classifier.\n\n    The number of unchanged pixels usually outnumber changed pixels and since they're highly\n    correlated over time, they should lie along the first principal axis while the changed pixels\n    lie along the second axis. However, since the principal components are calculated from the\n    covariance matrix computed for **all** pixels, the no-change axis might be poorly defined.\n    Iterated PCA solves this by calculating the principal components iteratively and weighting\n    each pixel by its probability to be no change pixels.\n\n    Accepted flags\n    --------------\n    - niter = Number of iterations IPCA should be run\n\n    References\n    ----------\n    - Wiemker, R. (1997). An iterative spectral-spatial Bayesian labeling approach for unsupervised\n    robust change detection on remotely sensed multispectral imagery. In Proceedings of the 7th\n    International Conference on Computer Analysis of Images and Patterns, volume LCNS 1296, pages\n    263\u2013370.\n    - Canty, M.J. (2019). Image Analysis, Classification, and Change Detection in Remote Sensing:\n    With Algorithms for Python (4th ed.). CRC Press. https://doi.org/10.1201/9780429464348\n    \"\"\"\n\n    @classmethod\n    def run(cls, im1: np.ndarray, im2: np.ndarray, **flags: Any) -&gt; np.ndarray:\n        \"\"\"Run IPCA algorithm.\n\n        Args:\n            im1 (np.ndarray): Image 1 array\n            im2 (np.ndarray): Image 2 array\n            **flags (dict): Flags for the algorithm\n\n        Run `changedet --algo ipca algo --help` for information on flags\n        \"\"\"\n        niter = flags.get(\"niter\", 5)\n        band_idx = flags.get(\"band\")\n        logger = flags[\"logger\"]\n\n        band_str = \"all bands\" if band_idx == -1 else \"band \" + str(band_idx)\n\n        logger.info(\"Running IPCA algorithm for %d iteration(s) on %s\", niter, band_str)\n\n        bands, rows, cols = im1.shape\n\n        cmaps = []\n        n_clusters = 2\n        for band in range(bands):\n            # TODO: Allow band sublist\n            if band_idx == -1:\n                logger.info(f\"Processing band {band + 1}\")\n            else:\n                logger.info(f\"Processing band {band_idx}\")\n\n            fim1 = im1[band].flatten()\n            fim2 = im2[band].flatten()\n\n            X = np.zeros((rows * cols, 2))\n            X[:, 0] = fim1 - np.mean(fim1)\n            X[:, 1] = fim2 - np.mean(fim2)\n\n            # Initial PCA\n            ows = OnlineWeightStats(2)\n            ows.update(X)\n            eivals, eigvecs = np.linalg.eigh(ows.cov)\n            eivals = eivals[::-1]\n            eigvecs = eigvecs[:, ::-1]\n\n            pcs = X @ eigvecs\n\n            gmm = GMM(n_clusters, 60)\n\n            for _ in range(niter):\n                # Calculate responsibility matrix\n                U = np.random.rand(X.shape[0], n_clusters)\n                for _ in range(n_clusters):\n                    sigma = np.sqrt(eivals[1])\n                    unfrozen = np.where(np.abs(pcs[:, 1]) &gt;= sigma)[0]\n                    frozen = np.where(np.abs(pcs[:, 1]) &lt; sigma)[0]\n                    U[frozen, 0] = 1.0\n                    U[frozen, 1] = 0.0\n                    for j in range(2):\n                        U[:, j] = U[:, j] / np.sum(U, 1)\n\n                r, _, _, _ = gmm.fit(X, U, unfrozen)\n\n                tmp = r[:, 0] + 1 - 1\n                ows.update(X, tmp)\n                eivals, eigvecs = np.linalg.eigh(ows.cov)\n                eivals = eivals[::-1]\n                eigvecs = eigvecs[:, ::-1]\n\n                pcs = X @ eigvecs\n\n            cmap = np.reshape(r[:, 1], (rows, cols))\n            cmaps.append(cmap)\n\n        return np.array(cmaps)\n</code></pre>"},{"location":"reference/algos/ipca.html#changedet.algos.ipca.IteratedPCA.run","title":"<code>run(im1, im2, **flags)</code>  <code>classmethod</code>","text":"<p>Run IPCA algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>im1</code> <code>ndarray</code> <p>Image 1 array</p> required <code>im2</code> <code>ndarray</code> <p>Image 2 array</p> required <code>**flags</code> <code>dict</code> <p>Flags for the algorithm</p> <code>{}</code> <p>Run <code>changedet --algo ipca algo --help</code> for information on flags</p> Source code in <code>changedet/algos/ipca.py</code> <pre><code>@classmethod\ndef run(cls, im1: np.ndarray, im2: np.ndarray, **flags: Any) -&gt; np.ndarray:\n    \"\"\"Run IPCA algorithm.\n\n    Args:\n        im1 (np.ndarray): Image 1 array\n        im2 (np.ndarray): Image 2 array\n        **flags (dict): Flags for the algorithm\n\n    Run `changedet --algo ipca algo --help` for information on flags\n    \"\"\"\n    niter = flags.get(\"niter\", 5)\n    band_idx = flags.get(\"band\")\n    logger = flags[\"logger\"]\n\n    band_str = \"all bands\" if band_idx == -1 else \"band \" + str(band_idx)\n\n    logger.info(\"Running IPCA algorithm for %d iteration(s) on %s\", niter, band_str)\n\n    bands, rows, cols = im1.shape\n\n    cmaps = []\n    n_clusters = 2\n    for band in range(bands):\n        # TODO: Allow band sublist\n        if band_idx == -1:\n            logger.info(f\"Processing band {band + 1}\")\n        else:\n            logger.info(f\"Processing band {band_idx}\")\n\n        fim1 = im1[band].flatten()\n        fim2 = im2[band].flatten()\n\n        X = np.zeros((rows * cols, 2))\n        X[:, 0] = fim1 - np.mean(fim1)\n        X[:, 1] = fim2 - np.mean(fim2)\n\n        # Initial PCA\n        ows = OnlineWeightStats(2)\n        ows.update(X)\n        eivals, eigvecs = np.linalg.eigh(ows.cov)\n        eivals = eivals[::-1]\n        eigvecs = eigvecs[:, ::-1]\n\n        pcs = X @ eigvecs\n\n        gmm = GMM(n_clusters, 60)\n\n        for _ in range(niter):\n            # Calculate responsibility matrix\n            U = np.random.rand(X.shape[0], n_clusters)\n            for _ in range(n_clusters):\n                sigma = np.sqrt(eivals[1])\n                unfrozen = np.where(np.abs(pcs[:, 1]) &gt;= sigma)[0]\n                frozen = np.where(np.abs(pcs[:, 1]) &lt; sigma)[0]\n                U[frozen, 0] = 1.0\n                U[frozen, 1] = 0.0\n                for j in range(2):\n                    U[:, j] = U[:, j] / np.sum(U, 1)\n\n            r, _, _, _ = gmm.fit(X, U, unfrozen)\n\n            tmp = r[:, 0] + 1 - 1\n            ows.update(X, tmp)\n            eivals, eigvecs = np.linalg.eigh(ows.cov)\n            eivals = eivals[::-1]\n            eigvecs = eigvecs[:, ::-1]\n\n            pcs = X @ eigvecs\n\n        cmap = np.reshape(r[:, 1], (rows, cols))\n        cmaps.append(cmap)\n\n    return np.array(cmaps)\n</code></pre>"},{"location":"reference/algos/irmad.html","title":"irmad","text":""},{"location":"reference/algos/irmad.html#changedet.algos.irmad.IRMAD","title":"<code>IRMAD</code>","text":"<p>             Bases: <code>MetaAlgo</code></p> <p>Iteratively Reweighted Multivariate Alteration Detection</p> <p>The Multivariate Alteration Detection (MAD) algorithm aims to identify a linear transformation that minimises the correlation between the canonical components of the two images thereby maximising change information. Iteratively Reweighted (IR)-MAD is an improvement on the MAD approach where observations are iteratively reweighted in order to establish a better no change background which allows better separability between change and no-change.</p>"},{"location":"reference/algos/irmad.html#changedet.algos.irmad.IRMAD--accepted-flags","title":"Accepted flags","text":"<ul> <li>niter = Number of iterations IRMAD should be run</li> <li>sig = Change map significance level</li> <li>icm = Initial change mask</li> </ul>"},{"location":"reference/algos/irmad.html#changedet.algos.irmad.IRMAD--references","title":"References","text":"<ul> <li>Nielsen, A. A. (2007). The regularized iteratively reweighted MAD method for change detection in multi- and hyperspectral data. IEEE Transactions on Image Processing, 16(2):463\u2013478. Internet http://www2.compute.dtu.dk/pubdb/pubs/4695-full.html.</li> </ul> Source code in <code>changedet/algos/irmad.py</code> <pre><code>@AlgoCatalog.register(\"irmad\")\nclass IRMAD(MetaAlgo):\n    \"\"\"Iteratively Reweighted Multivariate Alteration Detection\n\n    The Multivariate Alteration Detection (MAD) algorithm aims to identify a linear transformation\n    that minimises the correlation between the canonical components of the two images thereby\n    maximising change information. Iteratively Reweighted (IR)-MAD is an improvement on the MAD\n    approach where observations are iteratively reweighted in order to establish a better no change\n    background which allows better separability between change and no-change.\n\n    Accepted flags\n    --------------\n    - niter = Number of iterations IRMAD should be run\n    - sig = Change map significance level\n    - icm = Initial change mask\n\n    References\n    ----------\n    - Nielsen, A. A. (2007). The regularized iteratively reweighted MAD method for change detection\n    in multi- and hyperspectral data. IEEE Transactions on Image Processing, 16(2):463\u2013478. Internet\n    http://www2.compute.dtu.dk/pubdb/pubs/4695-full.html.\n\n\n    \"\"\"\n\n    @classmethod\n    def run(cls, im1: np.ndarray, im2: np.ndarray, **flags: Any) -&gt; np.ndarray:\n        \"\"\"Run IRMAD algorithm.\n\n        Args:\n            im1 (np.ndarray): Image 1 array\n            im2 (np.ndarray): Image 2 array\n            **flags (dict): Flags for the algorithm\n\n        Run `changedet --algo irmad algo_obj --help` for information on flags.\n        \"\"\"\n        niter = flags.get(\"niter\", 10)\n        sig = flags.get(\"sig\", 0.0001)\n        apply_icm = flags.get(\"icm\", False)\n        if apply_icm:\n            raise NotImplementedError(\n                \"Initial Change Mask is under construction and not ready for use\"\n            )\n        logger = flags[\"logger\"]\n        logger.info(\n            \"Running IRMAD algorithm for %d iteration(s) with significance level %f\",\n            niter,\n            sig,\n        )\n\n        ch1, r1, c1 = im1.shape\n\n        m = r1 * c1\n        N = ch1\n\n        im1r = im1.reshape(N, m).T\n        im2r = im2.reshape(N, m).T\n\n        # Calculate ICM\n        if apply_icm:\n            icm = InitialChangeMask()\n            change_mask = icm.prepare(im1, im2, plot=True)\n\n            if change_mask is None:\n                logger.warn(\"Invalid threshold. Skipping ICM\")\n                change_mask = np.ones((m, 1))\n            else:\n                change_mask = change_mask.reshape(m, 1)\n\n            # Apply change mask\n            im1r = im1r * change_mask\n            im2r = im2r * change_mask\n\n        # Center data\n        im1r = im1r - np.mean(im1r, 0)\n        im2r = im2r - np.mean(im2r, 0)\n\n        x = np.concatenate((im1r, im2r), axis=1)\n\n        # if not pvs:\n        #     pvs = np.ones(r1 * c1)\n        pvs = np.ones(r1 * c1, dtype=np.float32)\n        itr = 0\n\n        with tqdm(total=niter) as pbar:\n            while itr &lt; niter:\n                itr += 1\n                sigma, mean = np_weight_stats(x, pvs)\n                ms1 = mean[:N].T\n                ms2 = mean[N:].T\n                sigma11 = sigma[:ch1, :ch1]\n                sigma12 = sigma[:ch1, ch1:]\n                sigma21 = sigma[ch1:, :ch1]\n                sigma22 = sigma[ch1:, ch1:]\n                assert np.allclose(sigma21, sigma12.T)\n\n                A1 = sigma12 @ np.linalg.solve(sigma22, sigma12.T)\n                A2 = sigma12.T @ np.linalg.solve(sigma11, sigma12)\n\n                # Scipy's linalg.eig returns normalised eigenvectors\n                lamda1, eigvec1 = linalg.eigh(A1, sigma11)\n                lamda2, eigvec2 = linalg.eigh(A2, sigma22)\n\n                # sort eigenvalues &amp; eigenvectors in descending order\n                # TODO: Remove idx2. It's the same as idx\n                idx = np.argsort(lamda1)\n                lamda1 = lamda1[idx][::-1]\n                eigvec1 = eigvec1[:, idx][:, ::-1]\n\n                idx2 = np.argsort(lamda2)\n                lamda2 = lamda2[idx2][::-1]\n                eigvec2 = eigvec2[:, idx2][:, ::-1]\n\n                rho2 = lamda1  # or lamda2 they're the same\n                rho = np.sqrt(rho2)\n\n                # canonical correlations\n\n                # ensure positive correlation between each pair of canonical variates\n                diag = np.diag(eigvec1.T @ sigma12 @ eigvec2)\n                signs = np.diag(diag / np.abs(diag))  # Diagonal matrix of signs\n                eigvec2 = eigvec2 @ signs\n\n                # Calculate p value weights\n                sig2s = 2 * (1 - rho)\n                sig2s = np.reshape(np.tile(sig2s, [m]), (m, N))\n                ms1 = np.reshape(np.tile(ms1[0], [m]), (m, N))\n                ms2 = np.reshape(np.tile(ms2[0], [m]), (m, N))\n                cv1 = (im1r - ms1) @ eigvec1\n                cv2 = (im2r - ms2) @ eigvec2\n                mads = cv1 - cv2\n\n                chisqr = (np.square(mads) / sig2s).sum(axis=1)\n                # Upper tailed test\n                pvs = 1 - chi2(N).cdf(chisqr)\n                # np.ma.average expects 1D weights\n                pvs = pvs.squeeze()\n                pbar.update()\n\n        cmap = np.copy(mads)\n        idx = np.where(pvs &gt; sig)[0]\n        cmap[idx, :] = 0.0\n\n        cmap = cmap.T.reshape(im1.shape)  # Change map\n        mads = mads.T.reshape(im1.shape)  # MAD variates\n        chisqr = chisqr.reshape((1, r1, c1))\n        cmap = contrast_stretch(cmap, stretch_type=\"percentile\")\n\n        return cmap\n</code></pre>"},{"location":"reference/algos/irmad.html#changedet.algos.irmad.IRMAD.run","title":"<code>run(im1, im2, **flags)</code>  <code>classmethod</code>","text":"<p>Run IRMAD algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>im1</code> <code>ndarray</code> <p>Image 1 array</p> required <code>im2</code> <code>ndarray</code> <p>Image 2 array</p> required <code>**flags</code> <code>dict</code> <p>Flags for the algorithm</p> <code>{}</code> <p>Run <code>changedet --algo irmad algo_obj --help</code> for information on flags.</p> Source code in <code>changedet/algos/irmad.py</code> <pre><code>@classmethod\ndef run(cls, im1: np.ndarray, im2: np.ndarray, **flags: Any) -&gt; np.ndarray:\n    \"\"\"Run IRMAD algorithm.\n\n    Args:\n        im1 (np.ndarray): Image 1 array\n        im2 (np.ndarray): Image 2 array\n        **flags (dict): Flags for the algorithm\n\n    Run `changedet --algo irmad algo_obj --help` for information on flags.\n    \"\"\"\n    niter = flags.get(\"niter\", 10)\n    sig = flags.get(\"sig\", 0.0001)\n    apply_icm = flags.get(\"icm\", False)\n    if apply_icm:\n        raise NotImplementedError(\n            \"Initial Change Mask is under construction and not ready for use\"\n        )\n    logger = flags[\"logger\"]\n    logger.info(\n        \"Running IRMAD algorithm for %d iteration(s) with significance level %f\",\n        niter,\n        sig,\n    )\n\n    ch1, r1, c1 = im1.shape\n\n    m = r1 * c1\n    N = ch1\n\n    im1r = im1.reshape(N, m).T\n    im2r = im2.reshape(N, m).T\n\n    # Calculate ICM\n    if apply_icm:\n        icm = InitialChangeMask()\n        change_mask = icm.prepare(im1, im2, plot=True)\n\n        if change_mask is None:\n            logger.warn(\"Invalid threshold. Skipping ICM\")\n            change_mask = np.ones((m, 1))\n        else:\n            change_mask = change_mask.reshape(m, 1)\n\n        # Apply change mask\n        im1r = im1r * change_mask\n        im2r = im2r * change_mask\n\n    # Center data\n    im1r = im1r - np.mean(im1r, 0)\n    im2r = im2r - np.mean(im2r, 0)\n\n    x = np.concatenate((im1r, im2r), axis=1)\n\n    # if not pvs:\n    #     pvs = np.ones(r1 * c1)\n    pvs = np.ones(r1 * c1, dtype=np.float32)\n    itr = 0\n\n    with tqdm(total=niter) as pbar:\n        while itr &lt; niter:\n            itr += 1\n            sigma, mean = np_weight_stats(x, pvs)\n            ms1 = mean[:N].T\n            ms2 = mean[N:].T\n            sigma11 = sigma[:ch1, :ch1]\n            sigma12 = sigma[:ch1, ch1:]\n            sigma21 = sigma[ch1:, :ch1]\n            sigma22 = sigma[ch1:, ch1:]\n            assert np.allclose(sigma21, sigma12.T)\n\n            A1 = sigma12 @ np.linalg.solve(sigma22, sigma12.T)\n            A2 = sigma12.T @ np.linalg.solve(sigma11, sigma12)\n\n            # Scipy's linalg.eig returns normalised eigenvectors\n            lamda1, eigvec1 = linalg.eigh(A1, sigma11)\n            lamda2, eigvec2 = linalg.eigh(A2, sigma22)\n\n            # sort eigenvalues &amp; eigenvectors in descending order\n            # TODO: Remove idx2. It's the same as idx\n            idx = np.argsort(lamda1)\n            lamda1 = lamda1[idx][::-1]\n            eigvec1 = eigvec1[:, idx][:, ::-1]\n\n            idx2 = np.argsort(lamda2)\n            lamda2 = lamda2[idx2][::-1]\n            eigvec2 = eigvec2[:, idx2][:, ::-1]\n\n            rho2 = lamda1  # or lamda2 they're the same\n            rho = np.sqrt(rho2)\n\n            # canonical correlations\n\n            # ensure positive correlation between each pair of canonical variates\n            diag = np.diag(eigvec1.T @ sigma12 @ eigvec2)\n            signs = np.diag(diag / np.abs(diag))  # Diagonal matrix of signs\n            eigvec2 = eigvec2 @ signs\n\n            # Calculate p value weights\n            sig2s = 2 * (1 - rho)\n            sig2s = np.reshape(np.tile(sig2s, [m]), (m, N))\n            ms1 = np.reshape(np.tile(ms1[0], [m]), (m, N))\n            ms2 = np.reshape(np.tile(ms2[0], [m]), (m, N))\n            cv1 = (im1r - ms1) @ eigvec1\n            cv2 = (im2r - ms2) @ eigvec2\n            mads = cv1 - cv2\n\n            chisqr = (np.square(mads) / sig2s).sum(axis=1)\n            # Upper tailed test\n            pvs = 1 - chi2(N).cdf(chisqr)\n            # np.ma.average expects 1D weights\n            pvs = pvs.squeeze()\n            pbar.update()\n\n    cmap = np.copy(mads)\n    idx = np.where(pvs &gt; sig)[0]\n    cmap[idx, :] = 0.0\n\n    cmap = cmap.T.reshape(im1.shape)  # Change map\n    mads = mads.T.reshape(im1.shape)  # MAD variates\n    chisqr = chisqr.reshape((1, r1, c1))\n    cmap = contrast_stretch(cmap, stretch_type=\"percentile\")\n\n    return cmap\n</code></pre>"}]}