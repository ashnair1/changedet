{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"changedet \u00b6 Experimental repo for trying out classical change detection algorithms. Refer docs for further details.","title":"Home"},{"location":"index.html#changedet","text":"Experimental repo for trying out classical change detection algorithms. Refer docs for further details.","title":"changedet"},{"location":"SUMMARY.html","text":"Home Installation Usage API Reference","title":"SUMMARY"},{"location":"installation.html","text":"Installation From source \u00b6 The source for changedet can be downloaded from the Github repo . You can either clone the public repository: 1 $ git clone git://github.com/ashnair1/changedet Or download the tarball : 1 $ curl -OJL https://github.com/ashnair1/changedet/tarball/master Once you have a copy of the source, you can install it with: 1 $ pip install .","title":"Installation"},{"location":"installation.html#from-source","text":"The source for changedet can be downloaded from the Github repo . You can either clone the public repository: 1 $ git clone git://github.com/ashnair1/changedet Or download the tarball : 1 $ curl -OJL https://github.com/ashnair1/changedet/tarball/master Once you have a copy of the source, you can install it with: 1 $ pip install .","title":"From source"},{"location":"usage.html","text":"Usage Changedet uses fire for its CLI. Basic usage commands are given below. For running change detection on two images, you can run the following command 1 changedet --algo imgdiff run sample1.tif sample2.tif Get more information on algorithm used 1 changedet --algo imgdiff algo_obj --help Get more info on changedet pipeline 1 changedet --help List available algorithms 1 changedet list","title":"Usage"},{"location":"reference/SUMMARY.html","text":"changedet algos base catalog cva imgdiff ipca irmad cli pipeline utils","title":"SUMMARY"},{"location":"reference/cli.html","text":"changedet.cli \u00b6 Console script for changedet.","title":"cli"},{"location":"reference/cli.html#changedet.cli","text":"Console script for changedet.","title":"cli"},{"location":"reference/pipeline.html","text":"changedet.pipeline \u00b6 ChangeDetPipeline \u00b6 Basic pipeline for running change detection algorithms. Parameters: Name Type Description Default algo str Change detection algorithm to be used required Attributes: Name Type Description algo_name str Name of change detection algorithm algo_obj str Change detection algorithm object logger logging.Logger Logger object __init__ ( self , algo ) special \u00b6 Initialise Pipeline Parameters: Name Type Description Default algo str Change detection algorithm to be used required Source code in changedet/pipeline.py def __init__ ( self , algo : str ): \"\"\"Initialise Pipeline Args: algo (str): Change detection algorithm to be used \"\"\" self . algo_name = algo self . algo_obj = AlgoCatalog . get ( algo ) self . logger = init_logger ( \"changedet\" ) list () classmethod \u00b6 List available algorithms Source code in changedet/pipeline.py @classmethod def list ( cls ) -> None : \"\"\"List available algorithms\"\"\" print ( AlgoCatalog . list ()) read ( self , im1 , im2 , band ) \u00b6 Read and prepare images Parameters: Name Type Description Default im1 str Path to image 1 required im2 str Path to image 2 required band int Band selection required Exceptions: Type Description AssertionError If images are not in the same projection system AssertionError If images are not of same shape Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray] arr1 (numpy.ndarray): Image 1 array of shape (B, H, W) arr2 (numpy.ndarray): Image 2 array of shape (B, H, W) Source code in changedet/pipeline.py def read ( self , im1 : str , im2 : str , band : int ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"Read and prepare images Args: im1 (str): Path to image 1 im2 (str): Path to image 2 band (int): Band selection Raises: AssertionError: If images are not in the same projection system AssertionError: If images are not of same shape Returns: tuple: - arr1 (numpy.ndarray): Image 1 array of shape (B, H, W) - arr2 (numpy.ndarray): Image 2 array of shape (B, H, W) \"\"\" try : assert Path ( im1 ) . exists () and Path ( im2 ) . exists () except AssertionError : self . logger . critical ( \"Images not found\" ) raise arr1 , crs1 , self . meta1 = self . _read ( im1 , band ) arr2 , crs2 , self . meta2 = self . _read ( im2 , band ) try : assert crs1 == crs2 except AssertionError : self . logger . critical ( \"Images are not in the same projection system\" ) raise try : assert arr1 . shape == arr2 . shape except AssertionError : self . logger . critical ( \"Image array shapes do not match\" ) raise return arr1 , arr2 run ( self , im1 , im2 , band =- 1 , ** kwargs ) \u00b6 Run change detection on images Parameters: Name Type Description Default im1 str Path to image 1 required im2 str Path to image 2 required band int Band selection -1 Exceptions: Type Description AssertionError If no algorithm is specified Source code in changedet/pipeline.py def run ( self , im1 : str , im2 : str , band : int = - 1 , ** kwargs : Any ) -> None : \"\"\" Run change detection on images Args: im1 (str): Path to image 1 im2 (str): Path to image 2 band (int): Band selection Raises: AssertionError: If no algorithm is specified \"\"\" if not self . algo_obj : raise AssertionError ( \"Algorithm not specified\" ) im1a , im2a = self . read ( im1 , im2 , band ) # TODO: Decide whether algos should have their own loggers kwargs . update ({ \"logger\" : self . logger , \"band\" : band }) cmap = self . algo_obj . run ( im1a , im2a , ** kwargs ) self . write ( cmap ) write ( self , cmap ) \u00b6 Write change map to disk Parameters: Name Type Description Default cmap ndarray Change map of shape (B, H, W) required Source code in changedet/pipeline.py def write ( self , cmap : np . ndarray ) -> None : \"\"\"Write change map to disk Args: cmap (numpy.ndarray): Change map of shape (B, H, W) \"\"\" profile = self . meta1 outfile = f \" { self . algo_name } _cmap.tif\" # Bandwise change or Single band change cmap = np . expand_dims ( cmap , axis = 0 ) if len ( cmap . shape ) == 2 else cmap profile [ \"count\" ] = cmap . shape [ 0 ] with rio . Env (): with rio . open ( outfile , \"w\" , ** profile ) as dst : for i in range ( profile [ \"count\" ]): dst . write ( cmap [ i ], i + 1 ) self . logger . info ( \"Change map written to %s \" , outfile )","title":"pipeline"},{"location":"reference/pipeline.html#changedet.pipeline","text":"","title":"pipeline"},{"location":"reference/pipeline.html#changedet.pipeline.ChangeDetPipeline","text":"Basic pipeline for running change detection algorithms. Parameters: Name Type Description Default algo str Change detection algorithm to be used required Attributes: Name Type Description algo_name str Name of change detection algorithm algo_obj str Change detection algorithm object logger logging.Logger Logger object","title":"ChangeDetPipeline"},{"location":"reference/pipeline.html#changedet.pipeline.ChangeDetPipeline.__init__","text":"Initialise Pipeline Parameters: Name Type Description Default algo str Change detection algorithm to be used required Source code in changedet/pipeline.py def __init__ ( self , algo : str ): \"\"\"Initialise Pipeline Args: algo (str): Change detection algorithm to be used \"\"\" self . algo_name = algo self . algo_obj = AlgoCatalog . get ( algo ) self . logger = init_logger ( \"changedet\" )","title":"__init__()"},{"location":"reference/pipeline.html#changedet.pipeline.ChangeDetPipeline.list","text":"List available algorithms Source code in changedet/pipeline.py @classmethod def list ( cls ) -> None : \"\"\"List available algorithms\"\"\" print ( AlgoCatalog . list ())","title":"list()"},{"location":"reference/pipeline.html#changedet.pipeline.ChangeDetPipeline.read","text":"Read and prepare images Parameters: Name Type Description Default im1 str Path to image 1 required im2 str Path to image 2 required band int Band selection required Exceptions: Type Description AssertionError If images are not in the same projection system AssertionError If images are not of same shape Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray] arr1 (numpy.ndarray): Image 1 array of shape (B, H, W) arr2 (numpy.ndarray): Image 2 array of shape (B, H, W) Source code in changedet/pipeline.py def read ( self , im1 : str , im2 : str , band : int ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"Read and prepare images Args: im1 (str): Path to image 1 im2 (str): Path to image 2 band (int): Band selection Raises: AssertionError: If images are not in the same projection system AssertionError: If images are not of same shape Returns: tuple: - arr1 (numpy.ndarray): Image 1 array of shape (B, H, W) - arr2 (numpy.ndarray): Image 2 array of shape (B, H, W) \"\"\" try : assert Path ( im1 ) . exists () and Path ( im2 ) . exists () except AssertionError : self . logger . critical ( \"Images not found\" ) raise arr1 , crs1 , self . meta1 = self . _read ( im1 , band ) arr2 , crs2 , self . meta2 = self . _read ( im2 , band ) try : assert crs1 == crs2 except AssertionError : self . logger . critical ( \"Images are not in the same projection system\" ) raise try : assert arr1 . shape == arr2 . shape except AssertionError : self . logger . critical ( \"Image array shapes do not match\" ) raise return arr1 , arr2","title":"read()"},{"location":"reference/pipeline.html#changedet.pipeline.ChangeDetPipeline.run","text":"Run change detection on images Parameters: Name Type Description Default im1 str Path to image 1 required im2 str Path to image 2 required band int Band selection -1 Exceptions: Type Description AssertionError If no algorithm is specified Source code in changedet/pipeline.py def run ( self , im1 : str , im2 : str , band : int = - 1 , ** kwargs : Any ) -> None : \"\"\" Run change detection on images Args: im1 (str): Path to image 1 im2 (str): Path to image 2 band (int): Band selection Raises: AssertionError: If no algorithm is specified \"\"\" if not self . algo_obj : raise AssertionError ( \"Algorithm not specified\" ) im1a , im2a = self . read ( im1 , im2 , band ) # TODO: Decide whether algos should have their own loggers kwargs . update ({ \"logger\" : self . logger , \"band\" : band }) cmap = self . algo_obj . run ( im1a , im2a , ** kwargs ) self . write ( cmap )","title":"run()"},{"location":"reference/pipeline.html#changedet.pipeline.ChangeDetPipeline.write","text":"Write change map to disk Parameters: Name Type Description Default cmap ndarray Change map of shape (B, H, W) required Source code in changedet/pipeline.py def write ( self , cmap : np . ndarray ) -> None : \"\"\"Write change map to disk Args: cmap (numpy.ndarray): Change map of shape (B, H, W) \"\"\" profile = self . meta1 outfile = f \" { self . algo_name } _cmap.tif\" # Bandwise change or Single band change cmap = np . expand_dims ( cmap , axis = 0 ) if len ( cmap . shape ) == 2 else cmap profile [ \"count\" ] = cmap . shape [ 0 ] with rio . Env (): with rio . open ( outfile , \"w\" , ** profile ) as dst : for i in range ( profile [ \"count\" ]): dst . write ( cmap [ i ], i + 1 ) self . logger . info ( \"Change map written to %s \" , outfile )","title":"write()"},{"location":"reference/utils.html","text":"changedet.utils \u00b6 GMM \u00b6 e_step ( self , X , resp , means , cov , pi , sample_inds ) \u00b6 Expectation step Shape notation: 1 2 3 N: number of samples D: number of features K: number of mixture components Parameters: Name Type Description Default X ndarray Data matrix of shape (N, D) required resp ndarray Responsibility matrix of shape (N,K) required means ndarray Means array of shape (K, D) required cov ndarray Covariance matrix of shape (K,D,D) - full required pi ndarray Mixture weights of shape (K,) required sample_inds Union[Sequence[Sequence[Sequence[Sequence[Sequence[Any]]]]], numpy._array_like._SupportsArray[numpy.dtype], Sequence[numpy._array_like._SupportsArray[numpy.dtype]], Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]], Sequence[Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]]], Sequence[Sequence[Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]]]], bool, int, float, complex, str, bytes, Sequence[Union[bool, int, float, complex, str, bytes]], Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]], Sequence[Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]]], Sequence[Sequence[Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]]]]] Samples to be considered required Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray] resp (numpy.ndarray): Responsibility matrix of shape (N,K) wpdf (numpy.ndarray): Unnormalised responsibility matrix of shape (N,K) Source code in changedet/utils.py def e_step ( self , X : np . ndarray , resp : np . ndarray , means : np . ndarray , cov : np . ndarray , pi : np . ndarray , sample_inds : ArrayLike , ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"Expectation step Shape notation: N: number of samples D: number of features K: number of mixture components Args: X (numpy.ndarray): Data matrix of shape (N, D) resp (numpy.ndarray): Responsibility matrix of shape (N,K) means (numpy.ndarray): Means array of shape (K, D) cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - full pi (numpy.ndarray): Mixture weights of shape (K,) sample_inds (array-like): Samples to be considered Returns: tuple: - resp (numpy.ndarray): Responsibility matrix of shape (N,K) - wpdf (numpy.ndarray): Unnormalised responsibility matrix of shape (N,K) \"\"\" for k in range ( self . n_components ): resp [ sample_inds , k ] = pi [ k ] * multivariate_normal . pdf ( X [ sample_inds ], means [ k ], cov [ k ] ) wpdf = resp . copy () # For log likelihood computation # Safe normalisation a = np . sum ( resp , axis = 1 , keepdims = True ) idx = np . where ( a == 0 )[ 0 ] a [ idx ] = 1.0 resp = resp / a return resp , wpdf estimate_full_covariance ( X , resp , nk , means , reg_covar ) staticmethod \u00b6 Estimate full covariance matrix Shape notation: 1 2 3 N: number of samples D: number of features K: number of mixture components Parameters: Name Type Description Default X ndarray Data matrix of shape (N, D) required resp ndarray Responsibility matrix of shape (N,K) required nk ndarray Total responsibility per cluster of shape (K,) required means ndarray Means array of shape (K, D) required reg_covar float Regularisation added to diagonal of covariance matrix to ensure positive definiteness required Returns: Type Description ndarray cov (numpy.ndarray): Covariance matrix of shape (K,D,D) Source code in changedet/utils.py @staticmethod def estimate_full_covariance ( X : np . ndarray , resp : np . ndarray , nk : np . ndarray , means : np . ndarray , reg_covar : float , ) -> np . ndarray : \"\"\"Estimate full covariance matrix Shape notation: N: number of samples D: number of features K: number of mixture components Args: X (numpy.ndarray): Data matrix of shape (N, D) resp (numpy.ndarray): Responsibility matrix of shape (N,K) nk (numpy.ndarray): Total responsibility per cluster of shape (K,) means (numpy.ndarray): Means array of shape (K, D) reg_covar (float): Regularisation added to diagonal of covariance matrix \\ to ensure positive definiteness Returns: cov (numpy.ndarray): Covariance matrix of shape (K,D,D) \"\"\" n_components , n_features = means . shape cov = np . empty (( n_components , n_features , n_features )) for k in range ( n_components ): delta = X - means [ k ] cov [ k ] = ( np . dot ( resp [:, k ] * delta . T , delta ) / nk [ k ] + np . eye ( n_features ) * reg_covar ) return cov estimate_tied_covariance ( X , resp , nk , means , reg_covar ) staticmethod \u00b6 Estimate tied covariance matrix Shape notation: 1 2 3 N: number of samples D: number of features K: number of mixture components Parameters: Name Type Description Default X ndarray Data matrix of shape (N, D) required resp ndarray Responsibility matrix of shape (N,K) required nk ndarray Total responsibility per cluster of shape (K,) required means ndarray Means array of shape (K, D) required reg_covar float Regularisation added to diagonal of covariance matrix to ensure positive definiteness required Returns: Type Description ndarray cov (numpy.ndarray): Covariance matrix of shape (K,D,D) Source code in changedet/utils.py @staticmethod def estimate_tied_covariance ( X : np . ndarray , resp : np . ndarray , nk : np . ndarray , means : np . ndarray , reg_covar : float , ) -> np . ndarray : \"\"\"Estimate tied covariance matrix Shape notation: N: number of samples D: number of features K: number of mixture components Args: X (numpy.ndarray): Data matrix of shape (N, D) resp (numpy.ndarray): Responsibility matrix of shape (N,K) nk (numpy.ndarray): Total responsibility per cluster of shape (K,) means (numpy.ndarray): Means array of shape (K, D) reg_covar (float): Regularisation added to diagonal of covariance matrix \\ to ensure positive definiteness Returns: cov (numpy.ndarray): Covariance matrix of shape (K,D,D) \"\"\" n_components , n_features = means . shape avg_X2 = np . dot ( X . T , X ) avg_means2 = np . dot ( nk * means . T , means ) cov = ( avg_X2 - avg_means2 ) / nk . sum () + np . eye ( n_features ) * reg_covar # Convert (D,D) cov to (K,D,D) cov where all K cov matrices are equal cov = np . repeat ( cov [ np . newaxis ], n_components , axis = 0 ) return cov fit ( self , X , resp = None , sample_inds = None ) \u00b6 Fit a GMM to X with initial responsibility resp. If sample_inds are specified, only those indexes are considered. Parameters: Name Type Description Default X ndarray Data matrix required resp Optional[numpy.ndarray] Initial responsibility matrix. Defaults to None. None sample_inds Union[Sequence[Sequence[Sequence[Sequence[Sequence[Any]]]]], numpy._array_like._SupportsArray[numpy.dtype], Sequence[numpy._array_like._SupportsArray[numpy.dtype]], Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]], Sequence[Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]]], Sequence[Sequence[Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]]]], bool, int, float, complex, str, bytes, Sequence[Union[bool, int, float, complex, str, bytes]], Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]], Sequence[Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]]], Sequence[Sequence[Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]]]]] Sample indexes to be considered. Defaults to None. None Returns: Type Description ndarray resp (numpy.ndarray): Responsibility matrix Source code in changedet/utils.py def fit ( self , X : np . ndarray , resp : Optional [ np . ndarray ] = None , sample_inds : Optional [ ArrayLike ] = None , ) -> np . ndarray : \"\"\" Fit a GMM to X with initial responsibility resp. If sample_inds are specified, only those indexes are considered. Args: X (numpy.ndarray): Data matrix resp (numpy.ndarray, optional): Initial responsibility matrix. Defaults to None. sample_inds (array-like, optional): Sample indexes to be considered. Defaults to None. Returns: resp (numpy.ndarray): Responsibility matrix \"\"\" n_samples , _ = X . shape if sample_inds is None : sample_inds = range ( n_samples ) means , cov , pi = self . init_cluster_params ( X ) lls = [] if resp is None : resp = np . random . rand ( n_samples , self . n_components ) resp /= resp . sum ( axis = 1 , keepdims = True ) else : means , pi , cov = self . m_step ( X , resp ) # EM algorithm for i in range ( self . niter ): # resp_old = resp + 0.0 # E step resp , wpdf = self . e_step ( X , resp , means , cov , pi , sample_inds ) # M step means , pi , cov = self . m_step ( X , resp ) # resp_flat = resp.ravel() # resp_old_flat = resp_old.ravel() # idx = np.where(resp.flat)[0] # ll = np.sum(resp_old_flat[idx] * np.log(resp_flat[idx])) ll = np . log ( wpdf . sum ( axis = 1 )) . sum () lls . append ( ll ) # print(f\"Log-likelihood:{ll}\") if i > 1 and np . abs ( lls [ i ] - lls [ i - 1 ]) < self . tol : # print(\"Exiting\") break return resp , means , cov , pi init_cluster_params ( self , X ) \u00b6 Initialse cluster parameters Shape notation: 1 2 3 N: number of samples D: number of features K: number of mixture components Initialisation method: 1 2 3 Initialise means to a random data point in X Initialse cov to a spherical covariance matrix of variance 1 Initialse pi to uniform distribution Parameters: Name Type Description Default X ndarray Data matrix of shape (N,D) required Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray] means (numpy.ndarray): Means array of shape (K, D) cov (numpy.ndarray): Covariance matrix of shape (K,D,D) pi (numpy.ndarray): Mixture weights of shape (K,) Source code in changedet/utils.py def init_cluster_params ( self , X : np . ndarray ) -> Tuple [ np . ndarray , np . ndarray , np . ndarray ]: \"\"\"Initialse cluster parameters Shape notation: N: number of samples D: number of features K: number of mixture components Initialisation method: Initialise means to a random data point in X Initialse cov to a spherical covariance matrix of variance 1 Initialse pi to uniform distribution Args: X (numpy.ndarray): Data matrix of shape (N,D) Returns: tuple: - means (numpy.ndarray): Means array of shape (K, D) - cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - pi (numpy.ndarray): Mixture weights of shape (K,) \"\"\" n_samples , n_features = X . shape means = np . zeros (( self . n_components , n_features )) cov = np . zeros (( self . n_components , n_features , n_features )) # Initialise # Mean -> random data point # Cov -> spherical covariance - all clusters have same diagonal cov # matrix and diagonal elements are all equal for k in range ( self . n_components ): means [ k ] = X [ np . random . choice ( n_samples )] cov [ k ] = np . eye ( n_features ) pi = np . ones ( self . n_components ) / self . n_components return means , cov , pi m_step ( self , X , resp ) \u00b6 Maximisation step Shape notation: 1 2 3 N: number of samples D: number of features K: number of mixture components Parameters: Name Type Description Default X ndarray Data matrix of shape (N, D) required resp ndarray Responsibility matrix of shape (N,K) required Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray] means (numpy.ndarray): Means array of shape (K, D) cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - full pi (numpy.ndarray): Mixture weights of shape (K,) Source code in changedet/utils.py def m_step ( self , X : np . ndarray , resp : np . ndarray ) -> Tuple [ np . ndarray , np . ndarray , np . ndarray ]: \"\"\"Maximisation step Shape notation: N: number of samples D: number of features K: number of mixture components Args: X (numpy.ndarray): Data matrix of shape (N, D) resp (numpy.ndarray): Responsibility matrix of shape (N,K) Returns: tuple: - means (numpy.ndarray): Means array of shape (K, D) - cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - full - pi (numpy.ndarray): Mixture weights of shape (K,) \"\"\" # M step n_samples , _ = X . shape nk = resp . sum ( axis = 0 ) means = np . dot ( resp . T , X ) / nk [:, np . newaxis ] pi = nk / n_samples if self . cov_type == \"tied\" : cov = self . estimate_tied_covariance ( X , resp , nk , means , self . reg_covar ) else : cov = self . estimate_full_covariance ( X , resp , nk , means , self . reg_covar ) return means , pi , cov InitialChangeMask \u00b6 Initial Change Mask Create a change mask to remove strong changes and enable better radiometric normalisation. References \u00b6 P. R. Marpu, P. Gamba and M. J. Canty, \"Improving Change Detection Results of IR-MAD by Eliminating Strong Changes,\" in IEEE Geoscience and Remote Sensing Letters, vol. 8 no. 4, pp. 799-803, July 2011, doi:10.1109/LGRS.2011.2109697. roots ( mean , var , pi ) staticmethod \u00b6 Compute the threshold between the no-change and change distributions from the mean, variance and mixture weight (pi) of no change, change and ambigous distributions. Refer this gist for full derivation. Parameters: Name Type Description Default mean ndarray means of distributions required var ndarray variances of distributions required pi ndarray mixture weights required Returns: Type Description Tuple[float, float] Tuple[float, float]: thresholds Source code in changedet/utils.py @staticmethod def roots ( mean : np . ndarray , var : np . ndarray , pi : np . ndarray ) -> Tuple [ float , float ]: \"\"\"Compute the threshold between the no-change and change distributions from the mean, variance and mixture weight (pi) of no change, change and ambigous distributions. Refer this [gist](<https://gist.github.com/ashnair1/433ffbc1e747f80067f8a0439e346279>) for full derivation. Args: mean (np.ndarray): means of distributions var (np.ndarray): variances of distributions pi (np.ndarray): mixture weights Returns: Tuple[float, float]: thresholds \"\"\" std1 = np . sqrt ( var [ 0 ]) std2 = np . sqrt ( var [ 1 ]) k = np . log (( std1 * pi [ 1 ]) / ( std2 * pi [ 0 ])) n1 = var [ 1 ] * mean [ 0 ] - var [ 0 ] * mean [ 1 ] n2 = np . sqrt ( var [ 0 ] * var [ 1 ] * ( mean [ 0 ] - mean [ 1 ]) ** 2 + 0.5 * k * ( var [ 0 ] - var [ 1 ]) ) d1 = var [ 1 ] - var [ 0 ] root1 = ( n1 + n2 ) / d1 root2 = ( n1 - n2 ) / d1 return root1 , root2 check_pos_semi_def ( mat ) \u00b6 Test whether matrix is positive semi-definite Ref: https://scicomp.stackexchange.com/a/12984/39306 https://stackoverflow.com/a/63911811/10800115 Parameters: Name Type Description Default mat ndarray Input matrix required Returns: Type Description bool Source code in changedet/utils.py def check_pos_semi_def ( mat : np . ndarray ) -> bool : \"\"\"Test whether matrix is positive semi-definite Ref: - <https://scicomp.stackexchange.com/a/12984/39306> - <https://stackoverflow.com/a/63911811/10800115> Args: mat (np.ndarray): Input matrix Returns: bool: True if mat is positive semi-definite else False \"\"\" try : reg_mat = mat + np . eye ( mat . shape [ 0 ]) * 1e-3 np . linalg . cholesky ( reg_mat ) return True except np . linalg . LinAlgError : return False contrast_stretch ( img , * , target_type = 'uint8' , stretch_type = 'minmax' , percentile = ( 2 , 98 )) \u00b6 Change image distribution to cover full range of target_type. Types of contrast stretching: - minmax (Default) - percentile Parameters: Name Type Description Default img ndarray Input image required target_type str Target type of rescaled image. Defaults to \"uint8\". 'uint8' stretch_type str Types of contrast stretching. Defaults to \"minmax\". 'minmax' percentile Tuple[int, int] Cut off percentiles if stretch_type = \"percentile\". Defaults to (2, 98). (2, 98) Returns: Type Description ndarray scaled (numpy.ndarray): Rescaled image Source code in changedet/utils.py def contrast_stretch ( img : np . ndarray , * , target_type : str = \"uint8\" , stretch_type : str = \"minmax\" , percentile : Tuple [ int , int ] = ( 2 , 98 ), ) -> np . ndarray : \"\"\"Change image distribution to cover full range of target_type. Types of contrast stretching: - minmax (Default) - percentile Args: img (numpy.ndarray): Input image target_type (dtype): Target type of rescaled image. Defaults to \"uint8\". stretch_type (str): Types of contrast stretching. Defaults to \"minmax\". percentile (tuple): Cut off percentiles if stretch_type = \"percentile\". Defaults to (2, 98). Returns: scaled (numpy.ndarray): Rescaled image \"\"\" type_info = np . iinfo ( target_type ) minout = type_info . min maxout = type_info . max if stretch_type == \"percentile\" : lower , upper = np . nanpercentile ( img , percentile ) else : lower = np . min ( img ) upper = np . max ( img ) # Contrast Stretching a = ( maxout - minout ) / ( upper - lower ) b = minout - a * lower g = a * img + b return np . clip ( g , minout , maxout ) histplot ( xlist , xlabel , bins = 50 ) \u00b6 Plot multiple histograms in the same figure Parameters: Name Type Description Default xlist Union[Sequence[Sequence[Sequence[Sequence[Sequence[Any]]]]], numpy._array_like._SupportsArray[numpy.dtype], Sequence[numpy._array_like._SupportsArray[numpy.dtype]], Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]], Sequence[Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]]], Sequence[Sequence[Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]]]], bool, int, float, complex, str, bytes, Sequence[Union[bool, int, float, complex, str, bytes]], Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]], Sequence[Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]]], Sequence[Sequence[Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]]]]] Sequence required xlabel List[str] Sequence label required bins Optional[int] Histogram bins. Defaults to 50. 50 Returns: Type Description Figure matplotlib.figure.figure: Figure with histograms Source code in changedet/utils.py def histplot ( xlist : ArrayLike , xlabel : List [ str ], bins : Optional [ int ] = 50 ) -> Figure : \"\"\"Plot multiple histograms in the same figure Args: xlist (arraylike): Sequence xlabel (list[str]): Sequence label bins (int, optional): Histogram bins. Defaults to 50. Returns: matplotlib.figure.figure: Figure with histograms \"\"\" f = plt . figure () for i , j in zip ( xlist , xlabel ): plt . hist ( i [:, :, 0 ] . flatten (), bins = bins , label = j ) plt . legend () return f init_logger ( name = 'logger' , output = None ) \u00b6 Initialise changedet logger Parameters: Name Type Description Default name str Name of this logger. Defaults to \"logger\". 'logger' output Optional[str] Path to folder/file to write logs. If None, logs are not written None Source code in changedet/utils.py def init_logger ( name : str = \"logger\" , output : Optional [ str ] = None ) -> logging . Logger : \"\"\" Initialise changedet logger Args: name (str, optional): Name of this logger. Defaults to \"logger\". output (str, optional): Path to folder/file to write logs. If None, logs are not written \"\"\" logger = logging . getLogger ( name = name ) logger . setLevel ( logging . DEBUG ) # Output logs to terminal streamhandler = logging . StreamHandler ( sys . stdout ) streamhandler . setLevel ( logging . INFO ) streamhandler . setFormatter ( _ColorFormatter ( datefmt = \"%Y-%m- %d %H:%M:%S\" )) logger . addHandler ( streamhandler ) # Output logs to file if output : output_path = Path ( output ) logfile = ( output_path if output_path . suffix in [ \".txt\" , \".log\" ] else output_path / \"log.txt\" ) Path . mkdir ( output_path . parent ) filehandler = logging . FileHandler ( logfile ) filehandler . setLevel ( logging . DEBUG ) filehandler . setFormatter ( _ColorFormatter ( datefmt = \"%Y-%m- %d %H:%M:%S\" )) logger . addHandler ( filehandler ) return logger np_weight_stats ( x , ws = None ) \u00b6 Calculate weighted mean and sample covariance. Parameters: Name Type Description Default x ndarray Data matrix of shape (N,D) required ws Optional[numpy.ndarray] Weight vector of shape (N,). Defaults to None None Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray] wsigma (numpy.ndarray): Weighted covariance matrix wmean (numpy.ndarray): Weighted mean Source code in changedet/utils.py def np_weight_stats ( x : np . ndarray , ws : Optional [ np . ndarray ] = None ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"Calculate weighted mean and sample covariance. Args: x (numpy.ndarray): Data matrix of shape (N,D) ws (numpy.ndarray, optional): Weight vector of shape (N,). Defaults to None Returns: tuple: - wsigma (numpy.ndarray): Weighted covariance matrix - wmean (numpy.ndarray): Weighted mean \"\"\" # Uniform weight if ws is unspecified or array of zeros if ws is None or not np . any ( ws ): ws = np . ones ( x . shape [ 0 ]) mean = np . ma . average ( x , axis = 0 , weights = ws ) wmean = np . expand_dims ( mean . data , axis = 1 ) # (H*W,) -> (H*W,1) wsigma = np . cov ( x , rowvar = False , aweights = ws ) return wsigma , wmean","title":"utils"},{"location":"reference/utils.html#changedet.utils","text":"","title":"utils"},{"location":"reference/utils.html#changedet.utils.GMM","text":"","title":"GMM"},{"location":"reference/utils.html#changedet.utils.GMM.e_step","text":"Expectation step Shape notation: 1 2 3 N: number of samples D: number of features K: number of mixture components Parameters: Name Type Description Default X ndarray Data matrix of shape (N, D) required resp ndarray Responsibility matrix of shape (N,K) required means ndarray Means array of shape (K, D) required cov ndarray Covariance matrix of shape (K,D,D) - full required pi ndarray Mixture weights of shape (K,) required sample_inds Union[Sequence[Sequence[Sequence[Sequence[Sequence[Any]]]]], numpy._array_like._SupportsArray[numpy.dtype], Sequence[numpy._array_like._SupportsArray[numpy.dtype]], Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]], Sequence[Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]]], Sequence[Sequence[Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]]]], bool, int, float, complex, str, bytes, Sequence[Union[bool, int, float, complex, str, bytes]], Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]], Sequence[Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]]], Sequence[Sequence[Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]]]]] Samples to be considered required Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray] resp (numpy.ndarray): Responsibility matrix of shape (N,K) wpdf (numpy.ndarray): Unnormalised responsibility matrix of shape (N,K) Source code in changedet/utils.py def e_step ( self , X : np . ndarray , resp : np . ndarray , means : np . ndarray , cov : np . ndarray , pi : np . ndarray , sample_inds : ArrayLike , ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"Expectation step Shape notation: N: number of samples D: number of features K: number of mixture components Args: X (numpy.ndarray): Data matrix of shape (N, D) resp (numpy.ndarray): Responsibility matrix of shape (N,K) means (numpy.ndarray): Means array of shape (K, D) cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - full pi (numpy.ndarray): Mixture weights of shape (K,) sample_inds (array-like): Samples to be considered Returns: tuple: - resp (numpy.ndarray): Responsibility matrix of shape (N,K) - wpdf (numpy.ndarray): Unnormalised responsibility matrix of shape (N,K) \"\"\" for k in range ( self . n_components ): resp [ sample_inds , k ] = pi [ k ] * multivariate_normal . pdf ( X [ sample_inds ], means [ k ], cov [ k ] ) wpdf = resp . copy () # For log likelihood computation # Safe normalisation a = np . sum ( resp , axis = 1 , keepdims = True ) idx = np . where ( a == 0 )[ 0 ] a [ idx ] = 1.0 resp = resp / a return resp , wpdf","title":"e_step()"},{"location":"reference/utils.html#changedet.utils.GMM.estimate_full_covariance","text":"Estimate full covariance matrix Shape notation: 1 2 3 N: number of samples D: number of features K: number of mixture components Parameters: Name Type Description Default X ndarray Data matrix of shape (N, D) required resp ndarray Responsibility matrix of shape (N,K) required nk ndarray Total responsibility per cluster of shape (K,) required means ndarray Means array of shape (K, D) required reg_covar float Regularisation added to diagonal of covariance matrix to ensure positive definiteness required Returns: Type Description ndarray cov (numpy.ndarray): Covariance matrix of shape (K,D,D) Source code in changedet/utils.py @staticmethod def estimate_full_covariance ( X : np . ndarray , resp : np . ndarray , nk : np . ndarray , means : np . ndarray , reg_covar : float , ) -> np . ndarray : \"\"\"Estimate full covariance matrix Shape notation: N: number of samples D: number of features K: number of mixture components Args: X (numpy.ndarray): Data matrix of shape (N, D) resp (numpy.ndarray): Responsibility matrix of shape (N,K) nk (numpy.ndarray): Total responsibility per cluster of shape (K,) means (numpy.ndarray): Means array of shape (K, D) reg_covar (float): Regularisation added to diagonal of covariance matrix \\ to ensure positive definiteness Returns: cov (numpy.ndarray): Covariance matrix of shape (K,D,D) \"\"\" n_components , n_features = means . shape cov = np . empty (( n_components , n_features , n_features )) for k in range ( n_components ): delta = X - means [ k ] cov [ k ] = ( np . dot ( resp [:, k ] * delta . T , delta ) / nk [ k ] + np . eye ( n_features ) * reg_covar ) return cov","title":"estimate_full_covariance()"},{"location":"reference/utils.html#changedet.utils.GMM.estimate_tied_covariance","text":"Estimate tied covariance matrix Shape notation: 1 2 3 N: number of samples D: number of features K: number of mixture components Parameters: Name Type Description Default X ndarray Data matrix of shape (N, D) required resp ndarray Responsibility matrix of shape (N,K) required nk ndarray Total responsibility per cluster of shape (K,) required means ndarray Means array of shape (K, D) required reg_covar float Regularisation added to diagonal of covariance matrix to ensure positive definiteness required Returns: Type Description ndarray cov (numpy.ndarray): Covariance matrix of shape (K,D,D) Source code in changedet/utils.py @staticmethod def estimate_tied_covariance ( X : np . ndarray , resp : np . ndarray , nk : np . ndarray , means : np . ndarray , reg_covar : float , ) -> np . ndarray : \"\"\"Estimate tied covariance matrix Shape notation: N: number of samples D: number of features K: number of mixture components Args: X (numpy.ndarray): Data matrix of shape (N, D) resp (numpy.ndarray): Responsibility matrix of shape (N,K) nk (numpy.ndarray): Total responsibility per cluster of shape (K,) means (numpy.ndarray): Means array of shape (K, D) reg_covar (float): Regularisation added to diagonal of covariance matrix \\ to ensure positive definiteness Returns: cov (numpy.ndarray): Covariance matrix of shape (K,D,D) \"\"\" n_components , n_features = means . shape avg_X2 = np . dot ( X . T , X ) avg_means2 = np . dot ( nk * means . T , means ) cov = ( avg_X2 - avg_means2 ) / nk . sum () + np . eye ( n_features ) * reg_covar # Convert (D,D) cov to (K,D,D) cov where all K cov matrices are equal cov = np . repeat ( cov [ np . newaxis ], n_components , axis = 0 ) return cov","title":"estimate_tied_covariance()"},{"location":"reference/utils.html#changedet.utils.GMM.fit","text":"Fit a GMM to X with initial responsibility resp. If sample_inds are specified, only those indexes are considered. Parameters: Name Type Description Default X ndarray Data matrix required resp Optional[numpy.ndarray] Initial responsibility matrix. Defaults to None. None sample_inds Union[Sequence[Sequence[Sequence[Sequence[Sequence[Any]]]]], numpy._array_like._SupportsArray[numpy.dtype], Sequence[numpy._array_like._SupportsArray[numpy.dtype]], Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]], Sequence[Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]]], Sequence[Sequence[Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]]]], bool, int, float, complex, str, bytes, Sequence[Union[bool, int, float, complex, str, bytes]], Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]], Sequence[Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]]], Sequence[Sequence[Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]]]]] Sample indexes to be considered. Defaults to None. None Returns: Type Description ndarray resp (numpy.ndarray): Responsibility matrix Source code in changedet/utils.py def fit ( self , X : np . ndarray , resp : Optional [ np . ndarray ] = None , sample_inds : Optional [ ArrayLike ] = None , ) -> np . ndarray : \"\"\" Fit a GMM to X with initial responsibility resp. If sample_inds are specified, only those indexes are considered. Args: X (numpy.ndarray): Data matrix resp (numpy.ndarray, optional): Initial responsibility matrix. Defaults to None. sample_inds (array-like, optional): Sample indexes to be considered. Defaults to None. Returns: resp (numpy.ndarray): Responsibility matrix \"\"\" n_samples , _ = X . shape if sample_inds is None : sample_inds = range ( n_samples ) means , cov , pi = self . init_cluster_params ( X ) lls = [] if resp is None : resp = np . random . rand ( n_samples , self . n_components ) resp /= resp . sum ( axis = 1 , keepdims = True ) else : means , pi , cov = self . m_step ( X , resp ) # EM algorithm for i in range ( self . niter ): # resp_old = resp + 0.0 # E step resp , wpdf = self . e_step ( X , resp , means , cov , pi , sample_inds ) # M step means , pi , cov = self . m_step ( X , resp ) # resp_flat = resp.ravel() # resp_old_flat = resp_old.ravel() # idx = np.where(resp.flat)[0] # ll = np.sum(resp_old_flat[idx] * np.log(resp_flat[idx])) ll = np . log ( wpdf . sum ( axis = 1 )) . sum () lls . append ( ll ) # print(f\"Log-likelihood:{ll}\") if i > 1 and np . abs ( lls [ i ] - lls [ i - 1 ]) < self . tol : # print(\"Exiting\") break return resp , means , cov , pi","title":"fit()"},{"location":"reference/utils.html#changedet.utils.GMM.init_cluster_params","text":"Initialse cluster parameters Shape notation: 1 2 3 N: number of samples D: number of features K: number of mixture components Initialisation method: 1 2 3 Initialise means to a random data point in X Initialse cov to a spherical covariance matrix of variance 1 Initialse pi to uniform distribution Parameters: Name Type Description Default X ndarray Data matrix of shape (N,D) required Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray] means (numpy.ndarray): Means array of shape (K, D) cov (numpy.ndarray): Covariance matrix of shape (K,D,D) pi (numpy.ndarray): Mixture weights of shape (K,) Source code in changedet/utils.py def init_cluster_params ( self , X : np . ndarray ) -> Tuple [ np . ndarray , np . ndarray , np . ndarray ]: \"\"\"Initialse cluster parameters Shape notation: N: number of samples D: number of features K: number of mixture components Initialisation method: Initialise means to a random data point in X Initialse cov to a spherical covariance matrix of variance 1 Initialse pi to uniform distribution Args: X (numpy.ndarray): Data matrix of shape (N,D) Returns: tuple: - means (numpy.ndarray): Means array of shape (K, D) - cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - pi (numpy.ndarray): Mixture weights of shape (K,) \"\"\" n_samples , n_features = X . shape means = np . zeros (( self . n_components , n_features )) cov = np . zeros (( self . n_components , n_features , n_features )) # Initialise # Mean -> random data point # Cov -> spherical covariance - all clusters have same diagonal cov # matrix and diagonal elements are all equal for k in range ( self . n_components ): means [ k ] = X [ np . random . choice ( n_samples )] cov [ k ] = np . eye ( n_features ) pi = np . ones ( self . n_components ) / self . n_components return means , cov , pi","title":"init_cluster_params()"},{"location":"reference/utils.html#changedet.utils.GMM.m_step","text":"Maximisation step Shape notation: 1 2 3 N: number of samples D: number of features K: number of mixture components Parameters: Name Type Description Default X ndarray Data matrix of shape (N, D) required resp ndarray Responsibility matrix of shape (N,K) required Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray] means (numpy.ndarray): Means array of shape (K, D) cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - full pi (numpy.ndarray): Mixture weights of shape (K,) Source code in changedet/utils.py def m_step ( self , X : np . ndarray , resp : np . ndarray ) -> Tuple [ np . ndarray , np . ndarray , np . ndarray ]: \"\"\"Maximisation step Shape notation: N: number of samples D: number of features K: number of mixture components Args: X (numpy.ndarray): Data matrix of shape (N, D) resp (numpy.ndarray): Responsibility matrix of shape (N,K) Returns: tuple: - means (numpy.ndarray): Means array of shape (K, D) - cov (numpy.ndarray): Covariance matrix of shape (K,D,D) - full - pi (numpy.ndarray): Mixture weights of shape (K,) \"\"\" # M step n_samples , _ = X . shape nk = resp . sum ( axis = 0 ) means = np . dot ( resp . T , X ) / nk [:, np . newaxis ] pi = nk / n_samples if self . cov_type == \"tied\" : cov = self . estimate_tied_covariance ( X , resp , nk , means , self . reg_covar ) else : cov = self . estimate_full_covariance ( X , resp , nk , means , self . reg_covar ) return means , pi , cov","title":"m_step()"},{"location":"reference/utils.html#changedet.utils.InitialChangeMask","text":"Initial Change Mask Create a change mask to remove strong changes and enable better radiometric normalisation.","title":"InitialChangeMask"},{"location":"reference/utils.html#changedet.utils.InitialChangeMask--references","text":"P. R. Marpu, P. Gamba and M. J. Canty, \"Improving Change Detection Results of IR-MAD by Eliminating Strong Changes,\" in IEEE Geoscience and Remote Sensing Letters, vol. 8 no. 4, pp. 799-803, July 2011, doi:10.1109/LGRS.2011.2109697.","title":"References"},{"location":"reference/utils.html#changedet.utils.InitialChangeMask.roots","text":"Compute the threshold between the no-change and change distributions from the mean, variance and mixture weight (pi) of no change, change and ambigous distributions. Refer this gist for full derivation. Parameters: Name Type Description Default mean ndarray means of distributions required var ndarray variances of distributions required pi ndarray mixture weights required Returns: Type Description Tuple[float, float] Tuple[float, float]: thresholds Source code in changedet/utils.py @staticmethod def roots ( mean : np . ndarray , var : np . ndarray , pi : np . ndarray ) -> Tuple [ float , float ]: \"\"\"Compute the threshold between the no-change and change distributions from the mean, variance and mixture weight (pi) of no change, change and ambigous distributions. Refer this [gist](<https://gist.github.com/ashnair1/433ffbc1e747f80067f8a0439e346279>) for full derivation. Args: mean (np.ndarray): means of distributions var (np.ndarray): variances of distributions pi (np.ndarray): mixture weights Returns: Tuple[float, float]: thresholds \"\"\" std1 = np . sqrt ( var [ 0 ]) std2 = np . sqrt ( var [ 1 ]) k = np . log (( std1 * pi [ 1 ]) / ( std2 * pi [ 0 ])) n1 = var [ 1 ] * mean [ 0 ] - var [ 0 ] * mean [ 1 ] n2 = np . sqrt ( var [ 0 ] * var [ 1 ] * ( mean [ 0 ] - mean [ 1 ]) ** 2 + 0.5 * k * ( var [ 0 ] - var [ 1 ]) ) d1 = var [ 1 ] - var [ 0 ] root1 = ( n1 + n2 ) / d1 root2 = ( n1 - n2 ) / d1 return root1 , root2","title":"roots()"},{"location":"reference/utils.html#changedet.utils.check_pos_semi_def","text":"Test whether matrix is positive semi-definite Ref: https://scicomp.stackexchange.com/a/12984/39306 https://stackoverflow.com/a/63911811/10800115 Parameters: Name Type Description Default mat ndarray Input matrix required Returns: Type Description bool Source code in changedet/utils.py def check_pos_semi_def ( mat : np . ndarray ) -> bool : \"\"\"Test whether matrix is positive semi-definite Ref: - <https://scicomp.stackexchange.com/a/12984/39306> - <https://stackoverflow.com/a/63911811/10800115> Args: mat (np.ndarray): Input matrix Returns: bool: True if mat is positive semi-definite else False \"\"\" try : reg_mat = mat + np . eye ( mat . shape [ 0 ]) * 1e-3 np . linalg . cholesky ( reg_mat ) return True except np . linalg . LinAlgError : return False","title":"check_pos_semi_def()"},{"location":"reference/utils.html#changedet.utils.contrast_stretch","text":"Change image distribution to cover full range of target_type. Types of contrast stretching: - minmax (Default) - percentile Parameters: Name Type Description Default img ndarray Input image required target_type str Target type of rescaled image. Defaults to \"uint8\". 'uint8' stretch_type str Types of contrast stretching. Defaults to \"minmax\". 'minmax' percentile Tuple[int, int] Cut off percentiles if stretch_type = \"percentile\". Defaults to (2, 98). (2, 98) Returns: Type Description ndarray scaled (numpy.ndarray): Rescaled image Source code in changedet/utils.py def contrast_stretch ( img : np . ndarray , * , target_type : str = \"uint8\" , stretch_type : str = \"minmax\" , percentile : Tuple [ int , int ] = ( 2 , 98 ), ) -> np . ndarray : \"\"\"Change image distribution to cover full range of target_type. Types of contrast stretching: - minmax (Default) - percentile Args: img (numpy.ndarray): Input image target_type (dtype): Target type of rescaled image. Defaults to \"uint8\". stretch_type (str): Types of contrast stretching. Defaults to \"minmax\". percentile (tuple): Cut off percentiles if stretch_type = \"percentile\". Defaults to (2, 98). Returns: scaled (numpy.ndarray): Rescaled image \"\"\" type_info = np . iinfo ( target_type ) minout = type_info . min maxout = type_info . max if stretch_type == \"percentile\" : lower , upper = np . nanpercentile ( img , percentile ) else : lower = np . min ( img ) upper = np . max ( img ) # Contrast Stretching a = ( maxout - minout ) / ( upper - lower ) b = minout - a * lower g = a * img + b return np . clip ( g , minout , maxout )","title":"contrast_stretch()"},{"location":"reference/utils.html#changedet.utils.histplot","text":"Plot multiple histograms in the same figure Parameters: Name Type Description Default xlist Union[Sequence[Sequence[Sequence[Sequence[Sequence[Any]]]]], numpy._array_like._SupportsArray[numpy.dtype], Sequence[numpy._array_like._SupportsArray[numpy.dtype]], Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]], Sequence[Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]]], Sequence[Sequence[Sequence[Sequence[numpy._array_like._SupportsArray[numpy.dtype]]]]], bool, int, float, complex, str, bytes, Sequence[Union[bool, int, float, complex, str, bytes]], Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]], Sequence[Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]]], Sequence[Sequence[Sequence[Sequence[Union[bool, int, float, complex, str, bytes]]]]]] Sequence required xlabel List[str] Sequence label required bins Optional[int] Histogram bins. Defaults to 50. 50 Returns: Type Description Figure matplotlib.figure.figure: Figure with histograms Source code in changedet/utils.py def histplot ( xlist : ArrayLike , xlabel : List [ str ], bins : Optional [ int ] = 50 ) -> Figure : \"\"\"Plot multiple histograms in the same figure Args: xlist (arraylike): Sequence xlabel (list[str]): Sequence label bins (int, optional): Histogram bins. Defaults to 50. Returns: matplotlib.figure.figure: Figure with histograms \"\"\" f = plt . figure () for i , j in zip ( xlist , xlabel ): plt . hist ( i [:, :, 0 ] . flatten (), bins = bins , label = j ) plt . legend () return f","title":"histplot()"},{"location":"reference/utils.html#changedet.utils.init_logger","text":"Initialise changedet logger Parameters: Name Type Description Default name str Name of this logger. Defaults to \"logger\". 'logger' output Optional[str] Path to folder/file to write logs. If None, logs are not written None Source code in changedet/utils.py def init_logger ( name : str = \"logger\" , output : Optional [ str ] = None ) -> logging . Logger : \"\"\" Initialise changedet logger Args: name (str, optional): Name of this logger. Defaults to \"logger\". output (str, optional): Path to folder/file to write logs. If None, logs are not written \"\"\" logger = logging . getLogger ( name = name ) logger . setLevel ( logging . DEBUG ) # Output logs to terminal streamhandler = logging . StreamHandler ( sys . stdout ) streamhandler . setLevel ( logging . INFO ) streamhandler . setFormatter ( _ColorFormatter ( datefmt = \"%Y-%m- %d %H:%M:%S\" )) logger . addHandler ( streamhandler ) # Output logs to file if output : output_path = Path ( output ) logfile = ( output_path if output_path . suffix in [ \".txt\" , \".log\" ] else output_path / \"log.txt\" ) Path . mkdir ( output_path . parent ) filehandler = logging . FileHandler ( logfile ) filehandler . setLevel ( logging . DEBUG ) filehandler . setFormatter ( _ColorFormatter ( datefmt = \"%Y-%m- %d %H:%M:%S\" )) logger . addHandler ( filehandler ) return logger","title":"init_logger()"},{"location":"reference/utils.html#changedet.utils.np_weight_stats","text":"Calculate weighted mean and sample covariance. Parameters: Name Type Description Default x ndarray Data matrix of shape (N,D) required ws Optional[numpy.ndarray] Weight vector of shape (N,). Defaults to None None Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray] wsigma (numpy.ndarray): Weighted covariance matrix wmean (numpy.ndarray): Weighted mean Source code in changedet/utils.py def np_weight_stats ( x : np . ndarray , ws : Optional [ np . ndarray ] = None ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"Calculate weighted mean and sample covariance. Args: x (numpy.ndarray): Data matrix of shape (N,D) ws (numpy.ndarray, optional): Weight vector of shape (N,). Defaults to None Returns: tuple: - wsigma (numpy.ndarray): Weighted covariance matrix - wmean (numpy.ndarray): Weighted mean \"\"\" # Uniform weight if ws is unspecified or array of zeros if ws is None or not np . any ( ws ): ws = np . ones ( x . shape [ 0 ]) mean = np . ma . average ( x , axis = 0 , weights = ws ) wmean = np . expand_dims ( mean . data , axis = 1 ) # (H*W,) -> (H*W,1) wsigma = np . cov ( x , rowvar = False , aweights = ws ) return wsigma , wmean","title":"np_weight_stats()"},{"location":"reference/algos/base.html","text":"changedet.algos.base \u00b6 MetaAlgo \u00b6 Base class for an algorithm run ( im1 , im2 , ** kwargs ) classmethod \u00b6 Abstract method to run change detection Every algorithm will have at least one keyword argument - the global logger Source code in changedet/algos/base.py @abstractclassmethod def run ( cls , im1 : np . ndarray , im2 : np . ndarray , ** kwargs : Any ) -> np . ndarray : \"\"\" Abstract method to run change detection Every algorithm will have at least one keyword argument - the global logger \"\"\" assert \"logger\" in kwargs","title":"base"},{"location":"reference/algos/base.html#changedet.algos.base","text":"","title":"base"},{"location":"reference/algos/base.html#changedet.algos.base.MetaAlgo","text":"Base class for an algorithm","title":"MetaAlgo"},{"location":"reference/algos/base.html#changedet.algos.base.MetaAlgo.run","text":"Abstract method to run change detection Every algorithm will have at least one keyword argument - the global logger Source code in changedet/algos/base.py @abstractclassmethod def run ( cls , im1 : np . ndarray , im2 : np . ndarray , ** kwargs : Any ) -> np . ndarray : \"\"\" Abstract method to run change detection Every algorithm will have at least one keyword argument - the global logger \"\"\" assert \"logger\" in kwargs","title":"run()"},{"location":"reference/algos/catalog.html","text":"changedet.algos.catalog \u00b6 AlgoCatalog_ \u00b6 A global dictionary that stores information about the algorithms used and their corresponding pipeline. It contains a mapping of algorithm names to the algorithm class object. 1 2 3 4 5 6 7 >>> from changedet.algos import AlgoCatalog >>> import pprint >>> pprint.pprint(AlgoCatalog) {'cva': <class 'changedet.algos.cva.CVA'>, 'imgdiff': <class 'changedet.algos.imgdiff.ImageDiff'>, 'ipca': <class 'changedet.algos.ipca.IteratedPCA'>, 'irmad': <class 'changedet.algos.irmad.IRMAD'>} get ( self , name ) \u00b6 D.get(k[,d]) -> D[k] if k in D, else d. d defaults to None. Source code in changedet/algos/catalog.py def get ( self , name : str ) -> Type [ MetaAlgo ]: # type: ignore[override] try : f = self [ name ] except KeyError as e : if isinstance ( name , str ): avail_algos = \", \" . join ( list ( self . keys ())) raise KeyError ( f \"Algorithm { name } is not registered. Available algorithms are: { avail_algos } \" ) from e else : f = None return f list ( self ) \u00b6 List all registered algorithms. Returns: Type Description List[str] list[str]: List of algorithm names Source code in changedet/algos/catalog.py def list ( self ) -> List [ str ]: \"\"\"List all registered algorithms. Returns: list[str]: List of algorithm names \"\"\" return list ( sorted ( self . keys ())) register ( self , name ) \u00b6 Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in changedet/algos/catalog.py def register ( self , name : str ) -> Callable [[ Type [ MetaAlgo ]], Type [ MetaAlgo ]]: def inner_wrapper ( wrapped_class : Type [ MetaAlgo ]) -> Type [ MetaAlgo ]: if name in self . keys (): raise AssertionError ( f \"Algorithm { name } already exists.\" ) self [ name ] = wrapped_class return wrapped_class return inner_wrapper remove ( self , name ) \u00b6 Alias of pop . Source code in changedet/algos/catalog.py def remove ( self , name : str ) -> None : \"\"\" Alias of ``pop``. \"\"\" self . pop ( name )","title":"catalog"},{"location":"reference/algos/catalog.html#changedet.algos.catalog","text":"","title":"catalog"},{"location":"reference/algos/catalog.html#changedet.algos.catalog.AlgoCatalog_","text":"A global dictionary that stores information about the algorithms used and their corresponding pipeline. It contains a mapping of algorithm names to the algorithm class object. 1 2 3 4 5 6 7 >>> from changedet.algos import AlgoCatalog >>> import pprint >>> pprint.pprint(AlgoCatalog) {'cva': <class 'changedet.algos.cva.CVA'>, 'imgdiff': <class 'changedet.algos.imgdiff.ImageDiff'>, 'ipca': <class 'changedet.algos.ipca.IteratedPCA'>, 'irmad': <class 'changedet.algos.irmad.IRMAD'>}","title":"AlgoCatalog_"},{"location":"reference/algos/catalog.html#changedet.algos.catalog.AlgoCatalog_.get","text":"D.get(k[,d]) -> D[k] if k in D, else d. d defaults to None. Source code in changedet/algos/catalog.py def get ( self , name : str ) -> Type [ MetaAlgo ]: # type: ignore[override] try : f = self [ name ] except KeyError as e : if isinstance ( name , str ): avail_algos = \", \" . join ( list ( self . keys ())) raise KeyError ( f \"Algorithm { name } is not registered. Available algorithms are: { avail_algos } \" ) from e else : f = None return f","title":"get()"},{"location":"reference/algos/catalog.html#changedet.algos.catalog.AlgoCatalog_.list","text":"List all registered algorithms. Returns: Type Description List[str] list[str]: List of algorithm names Source code in changedet/algos/catalog.py def list ( self ) -> List [ str ]: \"\"\"List all registered algorithms. Returns: list[str]: List of algorithm names \"\"\" return list ( sorted ( self . keys ()))","title":"list()"},{"location":"reference/algos/catalog.html#changedet.algos.catalog.AlgoCatalog_.register","text":"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in changedet/algos/catalog.py def register ( self , name : str ) -> Callable [[ Type [ MetaAlgo ]], Type [ MetaAlgo ]]: def inner_wrapper ( wrapped_class : Type [ MetaAlgo ]) -> Type [ MetaAlgo ]: if name in self . keys (): raise AssertionError ( f \"Algorithm { name } already exists.\" ) self [ name ] = wrapped_class return wrapped_class return inner_wrapper","title":"register()"},{"location":"reference/algos/catalog.html#changedet.algos.catalog.AlgoCatalog_.remove","text":"Alias of pop . Source code in changedet/algos/catalog.py def remove ( self , name : str ) -> None : \"\"\" Alias of ``pop``. \"\"\" self . pop ( name )","title":"remove()"},{"location":"reference/algos/cva.html","text":"changedet.algos.cva \u00b6 CVA \u00b6 Calculate change vectors Builds a change map by calculating the amplitude map of the change vectors run ( im1 , im2 , ** flags ) classmethod \u00b6 Run Image Differencing algorithm Parameters: Name Type Description Default im1 ndarray Image 1 array required im2 ndarray Image 2 array required flags Any Flags for the algorithm {} Source code in changedet/algos/cva.py @classmethod def run ( cls , im1 : np . ndarray , im2 : np . ndarray , ** flags : Any ) -> np . ndarray : \"\"\"Run Image Differencing algorithm Args: im1 (np.ndarray): Image 1 array im2 (np.ndarray): Image 2 array flags (dict): Flags for the algorithm \"\"\" distance = flags . get ( \"distance\" , \"euclidean\" ) logger = flags [ \"logger\" ] assert distance in [ \"euclidean\" , \"manhattan\" ] # Calculate change vectors logger . info ( \"Calculating change vectors\" ) mag , theta = calc_cvs ( im1 , im2 , distance ) bcm = appy_threshold ( mag ) return bcm","title":"cva"},{"location":"reference/algos/cva.html#changedet.algos.cva","text":"","title":"cva"},{"location":"reference/algos/cva.html#changedet.algos.cva.CVA","text":"Calculate change vectors Builds a change map by calculating the amplitude map of the change vectors","title":"CVA"},{"location":"reference/algos/cva.html#changedet.algos.cva.CVA.run","text":"Run Image Differencing algorithm Parameters: Name Type Description Default im1 ndarray Image 1 array required im2 ndarray Image 2 array required flags Any Flags for the algorithm {} Source code in changedet/algos/cva.py @classmethod def run ( cls , im1 : np . ndarray , im2 : np . ndarray , ** flags : Any ) -> np . ndarray : \"\"\"Run Image Differencing algorithm Args: im1 (np.ndarray): Image 1 array im2 (np.ndarray): Image 2 array flags (dict): Flags for the algorithm \"\"\" distance = flags . get ( \"distance\" , \"euclidean\" ) logger = flags [ \"logger\" ] assert distance in [ \"euclidean\" , \"manhattan\" ] # Calculate change vectors logger . info ( \"Calculating change vectors\" ) mag , theta = calc_cvs ( im1 , im2 , distance ) bcm = appy_threshold ( mag ) return bcm","title":"run()"},{"location":"reference/algos/imgdiff.html","text":"changedet.algos.imgdiff \u00b6 ImageDiff \u00b6 Calculate difference map Builds a change map by calculating the difference between image 1 & image 2 run ( im1 , im2 , ** flags ) classmethod \u00b6 Run Image Differencing algorithm Parameters: Name Type Description Default im1 ndarray Image 1 array required im2 ndarray Image 2 array required flags Any Flags for the algorithm {} Source code in changedet/algos/imgdiff.py @classmethod def run ( cls , im1 : np . ndarray , im2 : np . ndarray , ** flags : Any ) -> np . ndarray : \"\"\"Run Image Differencing algorithm Args: im1 (np.ndarray): Image 1 array im2 (np.ndarray): Image 2 array flags (dict): Flags for the algorithm \"\"\" logger = flags [ \"logger\" ] # Calculate difference map logger . info ( \"Calculating difference map\" ) diff = im1 - im2 return diff","title":"imgdiff"},{"location":"reference/algos/imgdiff.html#changedet.algos.imgdiff","text":"","title":"imgdiff"},{"location":"reference/algos/imgdiff.html#changedet.algos.imgdiff.ImageDiff","text":"Calculate difference map Builds a change map by calculating the difference between image 1 & image 2","title":"ImageDiff"},{"location":"reference/algos/imgdiff.html#changedet.algos.imgdiff.ImageDiff.run","text":"Run Image Differencing algorithm Parameters: Name Type Description Default im1 ndarray Image 1 array required im2 ndarray Image 2 array required flags Any Flags for the algorithm {} Source code in changedet/algos/imgdiff.py @classmethod def run ( cls , im1 : np . ndarray , im2 : np . ndarray , ** flags : Any ) -> np . ndarray : \"\"\"Run Image Differencing algorithm Args: im1 (np.ndarray): Image 1 array im2 (np.ndarray): Image 2 array flags (dict): Flags for the algorithm \"\"\" logger = flags [ \"logger\" ] # Calculate difference map logger . info ( \"Calculating difference map\" ) diff = im1 - im2 return diff","title":"run()"},{"location":"reference/algos/ipca.html","text":"changedet.algos.ipca \u00b6 IteratedPCA \u00b6 Iterated PCA Change Classifier. The number of unchanged pixels usually outnumber changed pixels and since they're highly correlated over time, they should lie along the first principal axis while the changed pixels lie along the second axis. However, since the principal components are calculated from the covariance matrix computed for all pixels, the no-change axis might be poorly defined. Iterated PCA solves this by calculating the principal components iteratively and weighting each pixel by its probability to be no change pixels. Accepted flags \u00b6 niter = Number of iterations IPCA should be run References \u00b6 Wiemker, R. (1997). An iterative spectral-spatial Bayesian labeling approach for unsupervised robust change detection on remotely sensed multispectral imagery. In Proceedings of the 7th International Conference on Computer Analysis of Images and Patterns, volume LCNS 1296, pages 263\u2013370. Canty, M.J. (2019). Image Analysis, Classification, and Change Detection in Remote Sensing: With Algorithms for Python (4th ed.). CRC Press. https://doi.org/10.1201/9780429464348 run ( im1 , im2 , ** flags ) classmethod \u00b6 Run IPCA algorithm. Parameters: Name Type Description Default im1 ndarray Image 1 array required im2 ndarray Image 2 array required flags Any Flags for the algorithm {} Run changedet --algo ipca algo --help for information on flags Source code in changedet/algos/ipca.py @classmethod def run ( cls , im1 : np . ndarray , im2 : np . ndarray , ** flags : Any ) -> np . ndarray : \"\"\"Run IPCA algorithm. Args: im1 (np.ndarray): Image 1 array im2 (np.ndarray): Image 2 array flags (dict): Flags for the algorithm Run `changedet --algo ipca algo --help` for information on flags \"\"\" niter = flags . get ( \"niter\" , 5 ) band_idx = flags . get ( \"band\" ) logger = flags [ \"logger\" ] band_str = \"all bands\" if band_idx == - 1 else \"band \" + str ( band_idx ) logger . info ( \"Running IPCA algorithm for %d iteration(s) on %s \" , niter , band_str ) bands , rows , cols = im1 . shape cmaps = [] n_clusters = 2 for band in range ( bands ): # TODO: Allow band sublist if band_idx == - 1 : logger . info ( f \"Processing band { band + 1 } \" ) else : logger . info ( f \"Processing band { band_idx } \" ) fim1 = im1 [ band ] . flatten () fim2 = im2 [ band ] . flatten () X = np . zeros (( rows * cols , 2 )) X [:, 0 ] = fim1 - np . mean ( fim1 ) X [:, 1 ] = fim2 - np . mean ( fim2 ) # Initial PCA ows = OnlineWeightStats ( 2 ) ows . update ( X ) eivals , eigvecs = np . linalg . eigh ( ows . cov ) eivals = eivals [:: - 1 ] eigvecs = eigvecs [:, :: - 1 ] pcs = X @ eigvecs gmm = GMM ( n_clusters , 60 ) for _ in range ( niter ): # Calculate responsibility matrix U = np . random . rand ( X . shape [ 0 ], n_clusters ) for _ in range ( n_clusters ): sigma = np . sqrt ( eivals [ 1 ]) unfrozen = np . where ( np . abs ( pcs [:, 1 ]) >= sigma )[ 0 ] frozen = np . where ( np . abs ( pcs [:, 1 ]) < sigma )[ 0 ] U [ frozen , 0 ] = 1.0 U [ frozen , 1 ] = 0.0 for j in range ( 2 ): U [:, j ] = U [:, j ] / np . sum ( U , 1 ) r , _ , _ , _ = gmm . fit ( X , U , unfrozen ) tmp = r [:, 0 ] + 1 - 1 ows . update ( X , tmp ) eivals , eigvecs = np . linalg . eigh ( ows . cov ) eivals = eivals [:: - 1 ] eigvecs = eigvecs [:, :: - 1 ] pcs = X @ eigvecs cmap = np . reshape ( r [:, 1 ], ( rows , cols )) cmaps . append ( cmap ) return np . array ( cmaps )","title":"ipca"},{"location":"reference/algos/ipca.html#changedet.algos.ipca","text":"","title":"ipca"},{"location":"reference/algos/ipca.html#changedet.algos.ipca.IteratedPCA","text":"Iterated PCA Change Classifier. The number of unchanged pixels usually outnumber changed pixels and since they're highly correlated over time, they should lie along the first principal axis while the changed pixels lie along the second axis. However, since the principal components are calculated from the covariance matrix computed for all pixels, the no-change axis might be poorly defined. Iterated PCA solves this by calculating the principal components iteratively and weighting each pixel by its probability to be no change pixels.","title":"IteratedPCA"},{"location":"reference/algos/ipca.html#changedet.algos.ipca.IteratedPCA--accepted-flags","text":"niter = Number of iterations IPCA should be run","title":"Accepted flags"},{"location":"reference/algos/ipca.html#changedet.algos.ipca.IteratedPCA--references","text":"Wiemker, R. (1997). An iterative spectral-spatial Bayesian labeling approach for unsupervised robust change detection on remotely sensed multispectral imagery. In Proceedings of the 7th International Conference on Computer Analysis of Images and Patterns, volume LCNS 1296, pages 263\u2013370. Canty, M.J. (2019). Image Analysis, Classification, and Change Detection in Remote Sensing: With Algorithms for Python (4th ed.). CRC Press. https://doi.org/10.1201/9780429464348","title":"References"},{"location":"reference/algos/ipca.html#changedet.algos.ipca.IteratedPCA.run","text":"Run IPCA algorithm. Parameters: Name Type Description Default im1 ndarray Image 1 array required im2 ndarray Image 2 array required flags Any Flags for the algorithm {} Run changedet --algo ipca algo --help for information on flags Source code in changedet/algos/ipca.py @classmethod def run ( cls , im1 : np . ndarray , im2 : np . ndarray , ** flags : Any ) -> np . ndarray : \"\"\"Run IPCA algorithm. Args: im1 (np.ndarray): Image 1 array im2 (np.ndarray): Image 2 array flags (dict): Flags for the algorithm Run `changedet --algo ipca algo --help` for information on flags \"\"\" niter = flags . get ( \"niter\" , 5 ) band_idx = flags . get ( \"band\" ) logger = flags [ \"logger\" ] band_str = \"all bands\" if band_idx == - 1 else \"band \" + str ( band_idx ) logger . info ( \"Running IPCA algorithm for %d iteration(s) on %s \" , niter , band_str ) bands , rows , cols = im1 . shape cmaps = [] n_clusters = 2 for band in range ( bands ): # TODO: Allow band sublist if band_idx == - 1 : logger . info ( f \"Processing band { band + 1 } \" ) else : logger . info ( f \"Processing band { band_idx } \" ) fim1 = im1 [ band ] . flatten () fim2 = im2 [ band ] . flatten () X = np . zeros (( rows * cols , 2 )) X [:, 0 ] = fim1 - np . mean ( fim1 ) X [:, 1 ] = fim2 - np . mean ( fim2 ) # Initial PCA ows = OnlineWeightStats ( 2 ) ows . update ( X ) eivals , eigvecs = np . linalg . eigh ( ows . cov ) eivals = eivals [:: - 1 ] eigvecs = eigvecs [:, :: - 1 ] pcs = X @ eigvecs gmm = GMM ( n_clusters , 60 ) for _ in range ( niter ): # Calculate responsibility matrix U = np . random . rand ( X . shape [ 0 ], n_clusters ) for _ in range ( n_clusters ): sigma = np . sqrt ( eivals [ 1 ]) unfrozen = np . where ( np . abs ( pcs [:, 1 ]) >= sigma )[ 0 ] frozen = np . where ( np . abs ( pcs [:, 1 ]) < sigma )[ 0 ] U [ frozen , 0 ] = 1.0 U [ frozen , 1 ] = 0.0 for j in range ( 2 ): U [:, j ] = U [:, j ] / np . sum ( U , 1 ) r , _ , _ , _ = gmm . fit ( X , U , unfrozen ) tmp = r [:, 0 ] + 1 - 1 ows . update ( X , tmp ) eivals , eigvecs = np . linalg . eigh ( ows . cov ) eivals = eivals [:: - 1 ] eigvecs = eigvecs [:, :: - 1 ] pcs = X @ eigvecs cmap = np . reshape ( r [:, 1 ], ( rows , cols )) cmaps . append ( cmap ) return np . array ( cmaps )","title":"run()"},{"location":"reference/algos/irmad.html","text":"changedet.algos.irmad \u00b6 IRMAD \u00b6 Iteratively Reweighted Multivariate Alteration Detection The Multivariate Alteration Detection (MAD) algorithm aims to identify a linear transformation that minimises the correlation between the canonical components of the two images thereby maximising change information. Iteratively Reweighted (IR)-MAD is an improvement on the MAD approach where observations are iteratively reweighted in order to establish a better no change background which allows better separability between change and no-change. Accepted flags \u00b6 niter = Number of iterations IRMAD should be run sig = Change map significance level icm = Initial change mask References \u00b6 Nielsen, A. A. (2007). The regularized iteratively reweighted MAD method for change detection in multi- and hyperspectral data. IEEE Transactions on Image Processing, 16(2):463\u2013478. Internet http://www2.compute.dtu.dk/pubdb/pubs/4695-full.html. run ( im1 , im2 , ** flags ) classmethod \u00b6 Run IRMAD algorithm. Parameters: Name Type Description Default im1 ndarray Image 1 array required im2 ndarray Image 2 array required flags Any Flags for the algorithm {} Run changedet --algo irmad algo_obj --help for information on flags. Source code in changedet/algos/irmad.py @classmethod def run ( cls , im1 : np . ndarray , im2 : np . ndarray , ** flags : Any ) -> np . ndarray : \"\"\"Run IRMAD algorithm. Args: im1 (np.ndarray): Image 1 array im2 (np.ndarray): Image 2 array flags (dict): Flags for the algorithm Run `changedet --algo irmad algo_obj --help` for information on flags. \"\"\" niter = flags . get ( \"niter\" , 10 ) sig = flags . get ( \"sig\" , 0.0001 ) apply_icm = flags . get ( \"icm\" , False ) if apply_icm : raise NotImplementedError ( \"Initial Change Mask is under construction and not ready for use\" ) logger = flags [ \"logger\" ] logger . info ( \"Running IRMAD algorithm for %d iteration(s) with significance level %f \" , niter , sig , ) ch1 , r1 , c1 = im1 . shape m = r1 * c1 N = ch1 im1r = im1 . reshape ( N , m ) . T im2r = im2 . reshape ( N , m ) . T # Calculate ICM if apply_icm : icm = InitialChangeMask () change_mask = icm . prepare ( im1 , im2 , plot = True ) if change_mask is None : logger . warn ( \"Invalid threshold. Skipping ICM\" ) change_mask = np . ones (( m , 1 )) else : change_mask = change_mask . reshape ( m , 1 ) # Apply change mask im1r = im1r * change_mask im2r = im2r * change_mask # Center data im1r = im1r - np . mean ( im1r , 0 ) im2r = im2r - np . mean ( im2r , 0 ) x = np . concatenate (( im1r , im2r ), axis = 1 ) # if not pvs: # pvs = np.ones(r1 * c1) pvs = np . ones ( r1 * c1 , dtype = np . float32 ) itr = 0 with tqdm ( total = niter ) as pbar : while itr < niter : itr += 1 sigma , mean = np_weight_stats ( x , pvs ) ms1 = mean [: N ] . T ms2 = mean [ N :] . T sigma11 = sigma [: ch1 , : ch1 ] sigma12 = sigma [: ch1 , ch1 :] sigma21 = sigma [ ch1 :, : ch1 ] sigma22 = sigma [ ch1 :, ch1 :] assert np . allclose ( sigma21 , sigma12 . T ) A1 = sigma12 @ np . linalg . solve ( sigma22 , sigma12 . T ) A2 = sigma12 . T @ np . linalg . solve ( sigma11 , sigma12 ) # Scipy's linalg.eig returns normalised eigenvectors lamda1 , eigvec1 = linalg . eigh ( A1 , sigma11 ) lamda2 , eigvec2 = linalg . eigh ( A2 , sigma22 ) # sort eigenvalues & eigenvectors in descending order # TODO: Remove idx2. It's the same as idx idx = np . argsort ( lamda1 ) lamda1 = lamda1 [ idx ][:: - 1 ] eigvec1 = eigvec1 [:, idx ][:, :: - 1 ] idx2 = np . argsort ( lamda2 ) lamda2 = lamda2 [ idx2 ][:: - 1 ] eigvec2 = eigvec2 [:, idx2 ][:, :: - 1 ] rho2 = lamda1 # or lamda2 they're the same rho = np . sqrt ( rho2 ) # canonical correlations # ensure positive correlation between each pair of canonical variates diag = np . diag ( eigvec1 . T @ sigma12 @ eigvec2 ) signs = np . diag ( diag / np . abs ( diag )) # Diagonal matrix of signs eigvec2 = eigvec2 @ signs # Calculate p value weights sig2s = 2 * ( 1 - rho ) sig2s = np . reshape ( np . tile ( sig2s , [ m ]), ( m , N )) ms1 = np . reshape ( np . tile ( ms1 [ 0 ], [ m ]), ( m , N )) ms2 = np . reshape ( np . tile ( ms2 [ 0 ], [ m ]), ( m , N )) cv1 = ( im1r - ms1 ) @ eigvec1 cv2 = ( im2r - ms2 ) @ eigvec2 mads = cv1 - cv2 chisqr = ( np . square ( mads ) / sig2s ) . sum ( axis = 1 ) # Upper tailed test pvs = 1 - chi2 ( N ) . cdf ( chisqr ) # np.ma.average expects 1D weights pvs = pvs . squeeze () pbar . update () cmap = np . copy ( mads ) idx = np . where ( pvs > sig )[ 0 ] cmap [ idx , :] = 0.0 cmap = cmap . T . reshape ( im1 . shape ) # Change map mads = mads . T . reshape ( im1 . shape ) # MAD variates chisqr = chisqr . reshape (( 1 , r1 , c1 )) cmap = contrast_stretch ( cmap , stretch_type = \"percentile\" ) return cmap","title":"irmad"},{"location":"reference/algos/irmad.html#changedet.algos.irmad","text":"","title":"irmad"},{"location":"reference/algos/irmad.html#changedet.algos.irmad.IRMAD","text":"Iteratively Reweighted Multivariate Alteration Detection The Multivariate Alteration Detection (MAD) algorithm aims to identify a linear transformation that minimises the correlation between the canonical components of the two images thereby maximising change information. Iteratively Reweighted (IR)-MAD is an improvement on the MAD approach where observations are iteratively reweighted in order to establish a better no change background which allows better separability between change and no-change.","title":"IRMAD"},{"location":"reference/algos/irmad.html#changedet.algos.irmad.IRMAD--accepted-flags","text":"niter = Number of iterations IRMAD should be run sig = Change map significance level icm = Initial change mask","title":"Accepted flags"},{"location":"reference/algos/irmad.html#changedet.algos.irmad.IRMAD--references","text":"Nielsen, A. A. (2007). The regularized iteratively reweighted MAD method for change detection in multi- and hyperspectral data. IEEE Transactions on Image Processing, 16(2):463\u2013478. Internet http://www2.compute.dtu.dk/pubdb/pubs/4695-full.html.","title":"References"},{"location":"reference/algos/irmad.html#changedet.algos.irmad.IRMAD.run","text":"Run IRMAD algorithm. Parameters: Name Type Description Default im1 ndarray Image 1 array required im2 ndarray Image 2 array required flags Any Flags for the algorithm {} Run changedet --algo irmad algo_obj --help for information on flags. Source code in changedet/algos/irmad.py @classmethod def run ( cls , im1 : np . ndarray , im2 : np . ndarray , ** flags : Any ) -> np . ndarray : \"\"\"Run IRMAD algorithm. Args: im1 (np.ndarray): Image 1 array im2 (np.ndarray): Image 2 array flags (dict): Flags for the algorithm Run `changedet --algo irmad algo_obj --help` for information on flags. \"\"\" niter = flags . get ( \"niter\" , 10 ) sig = flags . get ( \"sig\" , 0.0001 ) apply_icm = flags . get ( \"icm\" , False ) if apply_icm : raise NotImplementedError ( \"Initial Change Mask is under construction and not ready for use\" ) logger = flags [ \"logger\" ] logger . info ( \"Running IRMAD algorithm for %d iteration(s) with significance level %f \" , niter , sig , ) ch1 , r1 , c1 = im1 . shape m = r1 * c1 N = ch1 im1r = im1 . reshape ( N , m ) . T im2r = im2 . reshape ( N , m ) . T # Calculate ICM if apply_icm : icm = InitialChangeMask () change_mask = icm . prepare ( im1 , im2 , plot = True ) if change_mask is None : logger . warn ( \"Invalid threshold. Skipping ICM\" ) change_mask = np . ones (( m , 1 )) else : change_mask = change_mask . reshape ( m , 1 ) # Apply change mask im1r = im1r * change_mask im2r = im2r * change_mask # Center data im1r = im1r - np . mean ( im1r , 0 ) im2r = im2r - np . mean ( im2r , 0 ) x = np . concatenate (( im1r , im2r ), axis = 1 ) # if not pvs: # pvs = np.ones(r1 * c1) pvs = np . ones ( r1 * c1 , dtype = np . float32 ) itr = 0 with tqdm ( total = niter ) as pbar : while itr < niter : itr += 1 sigma , mean = np_weight_stats ( x , pvs ) ms1 = mean [: N ] . T ms2 = mean [ N :] . T sigma11 = sigma [: ch1 , : ch1 ] sigma12 = sigma [: ch1 , ch1 :] sigma21 = sigma [ ch1 :, : ch1 ] sigma22 = sigma [ ch1 :, ch1 :] assert np . allclose ( sigma21 , sigma12 . T ) A1 = sigma12 @ np . linalg . solve ( sigma22 , sigma12 . T ) A2 = sigma12 . T @ np . linalg . solve ( sigma11 , sigma12 ) # Scipy's linalg.eig returns normalised eigenvectors lamda1 , eigvec1 = linalg . eigh ( A1 , sigma11 ) lamda2 , eigvec2 = linalg . eigh ( A2 , sigma22 ) # sort eigenvalues & eigenvectors in descending order # TODO: Remove idx2. It's the same as idx idx = np . argsort ( lamda1 ) lamda1 = lamda1 [ idx ][:: - 1 ] eigvec1 = eigvec1 [:, idx ][:, :: - 1 ] idx2 = np . argsort ( lamda2 ) lamda2 = lamda2 [ idx2 ][:: - 1 ] eigvec2 = eigvec2 [:, idx2 ][:, :: - 1 ] rho2 = lamda1 # or lamda2 they're the same rho = np . sqrt ( rho2 ) # canonical correlations # ensure positive correlation between each pair of canonical variates diag = np . diag ( eigvec1 . T @ sigma12 @ eigvec2 ) signs = np . diag ( diag / np . abs ( diag )) # Diagonal matrix of signs eigvec2 = eigvec2 @ signs # Calculate p value weights sig2s = 2 * ( 1 - rho ) sig2s = np . reshape ( np . tile ( sig2s , [ m ]), ( m , N )) ms1 = np . reshape ( np . tile ( ms1 [ 0 ], [ m ]), ( m , N )) ms2 = np . reshape ( np . tile ( ms2 [ 0 ], [ m ]), ( m , N )) cv1 = ( im1r - ms1 ) @ eigvec1 cv2 = ( im2r - ms2 ) @ eigvec2 mads = cv1 - cv2 chisqr = ( np . square ( mads ) / sig2s ) . sum ( axis = 1 ) # Upper tailed test pvs = 1 - chi2 ( N ) . cdf ( chisqr ) # np.ma.average expects 1D weights pvs = pvs . squeeze () pbar . update () cmap = np . copy ( mads ) idx = np . where ( pvs > sig )[ 0 ] cmap [ idx , :] = 0.0 cmap = cmap . T . reshape ( im1 . shape ) # Change map mads = mads . T . reshape ( im1 . shape ) # MAD variates chisqr = chisqr . reshape (( 1 , r1 , c1 )) cmap = contrast_stretch ( cmap , stretch_type = \"percentile\" ) return cmap","title":"run()"}]}